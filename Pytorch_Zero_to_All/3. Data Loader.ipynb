{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim, from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('diabetes.csv.gz', delimiter = ',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:,0:-1])\n",
    "        self.y_data = torch.from_numpy(xy[:,[-1]])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = 32, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.l1 = nn.Linear(8,4)\n",
    "        self.l2 = nn.Linear(4,6)\n",
    "        self.l3 = nn.Linear(6,1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "    \n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction = 'mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.6248021125793457\n",
      "0 1 0.683029294013977\n",
      "0 2 0.6826573610305786\n",
      "0 3 0.6068469882011414\n",
      "0 4 0.6243172287940979\n",
      "0 5 0.6639662384986877\n",
      "0 6 0.7031328082084656\n",
      "0 7 0.5877219438552856\n",
      "0 8 0.7031122446060181\n",
      "0 9 0.663367748260498\n",
      "0 10 0.5885205268859863\n",
      "0 11 0.6052546501159668\n",
      "0 12 0.683830976486206\n",
      "0 13 0.6241841316223145\n",
      "0 14 0.6635021567344666\n",
      "0 15 0.5852497816085815\n",
      "0 16 0.5416647791862488\n",
      "0 17 0.6873622536659241\n",
      "0 18 0.7074202299118042\n",
      "0 19 0.6235504150390625\n",
      "0 20 0.6234683394432068\n",
      "0 21 0.6854928135871887\n",
      "0 22 0.7046328783035278\n",
      "0 23 0.6459272503852844\n",
      "1 0 0.6436824798583984\n",
      "1 1 0.6441084146499634\n",
      "1 2 0.7222802639007568\n",
      "1 3 0.6816702485084534\n",
      "1 4 0.6081116795539856\n",
      "1 5 0.6815614104270935\n",
      "1 6 0.6809173226356506\n",
      "1 7 0.608758270740509\n",
      "1 8 0.6446368098258972\n",
      "1 9 0.7006134986877441\n",
      "1 10 0.6268171668052673\n",
      "1 11 0.5522536039352417\n",
      "1 12 0.5651386380195618\n",
      "1 13 0.6435560584068298\n",
      "1 14 0.6235425472259521\n",
      "1 15 0.6650934219360352\n",
      "1 16 0.7064365148544312\n",
      "1 17 0.604262113571167\n",
      "1 18 0.6643145084381104\n",
      "1 19 0.7444945573806763\n",
      "1 20 0.6062459945678711\n",
      "1 21 0.6051826477050781\n",
      "1 22 0.623620331287384\n",
      "1 23 0.6737569570541382\n",
      "2 0 0.6442922949790955\n",
      "2 1 0.624248206615448\n",
      "2 2 0.6844110488891602\n",
      "2 3 0.644550085067749\n",
      "2 4 0.7231327295303345\n",
      "2 5 0.6067982316017151\n",
      "2 6 0.6242919564247131\n",
      "2 7 0.6047571897506714\n",
      "2 8 0.5433176755905151\n",
      "2 9 0.6442610621452332\n",
      "2 10 0.6436505913734436\n",
      "2 11 0.7078906297683716\n",
      "2 12 0.5622920393943787\n",
      "2 13 0.6440161466598511\n",
      "2 14 0.7508148550987244\n",
      "2 15 0.6437804698944092\n",
      "2 16 0.6639991998672485\n",
      "2 17 0.6638729572296143\n",
      "2 18 0.68269944190979\n",
      "2 19 0.6252394318580627\n",
      "2 20 0.6825301647186279\n",
      "2 21 0.5873131155967712\n",
      "2 22 0.6636658310890198\n",
      "2 23 0.6463573575019836\n",
      "3 0 0.7612580060958862\n",
      "3 1 0.7163838148117065\n",
      "3 2 0.6448405981063843\n",
      "3 3 0.6795417070388794\n",
      "3 4 0.6108872890472412\n",
      "3 5 0.6802831292152405\n",
      "3 6 0.7490823864936829\n",
      "3 7 0.6941498517990112\n",
      "3 8 0.6773231625556946\n",
      "3 9 0.61607426404953\n",
      "3 10 0.5977717638015747\n",
      "3 11 0.5765730142593384\n",
      "3 12 0.6080435514450073\n",
      "3 13 0.624728262424469\n",
      "3 14 0.5670773386955261\n",
      "3 15 0.5826175808906555\n",
      "3 16 0.6445660591125488\n",
      "3 17 0.6021796464920044\n",
      "3 18 0.601006269454956\n",
      "3 19 0.6007595062255859\n",
      "3 20 0.5324831604957581\n",
      "3 21 0.7160329222679138\n",
      "3 22 0.7575803995132446\n",
      "3 23 0.6762548089027405\n",
      "4 0 0.7263336777687073\n",
      "4 1 0.6045045852661133\n",
      "4 2 0.764942467212677\n",
      "4 3 0.700404703617096\n",
      "4 4 0.5723523497581482\n",
      "4 5 0.5482766628265381\n",
      "4 6 0.6440522074699402\n",
      "4 7 0.5420495867729187\n",
      "4 8 0.7530680894851685\n",
      "4 9 0.6235901713371277\n",
      "4 10 0.6229735016822815\n",
      "4 11 0.6651946306228638\n",
      "4 12 0.6233202815055847\n",
      "4 13 0.6850947737693787\n",
      "4 14 0.6846674084663391\n",
      "4 15 0.6244618892669678\n",
      "4 16 0.6840841770172119\n",
      "4 17 0.7025300860404968\n",
      "4 18 0.6627153158187866\n",
      "4 19 0.6629366874694824\n",
      "4 20 0.53365558385849\n",
      "4 21 0.6239438056945801\n",
      "4 22 0.6435577869415283\n",
      "4 23 0.6181681752204895\n",
      "5 0 0.6647096276283264\n",
      "5 1 0.643820583820343\n",
      "5 2 0.7459858655929565\n",
      "5 3 0.6819369792938232\n",
      "5 4 0.7188142538070679\n",
      "5 5 0.6622350811958313\n",
      "5 6 0.6972083449363708\n",
      "5 7 0.6282528638839722\n",
      "5 8 0.5579489469528198\n",
      "5 9 0.6437278389930725\n",
      "5 10 0.7764950394630432\n",
      "5 11 0.7140433192253113\n",
      "5 12 0.5800893306732178\n",
      "5 13 0.5742260217666626\n",
      "5 14 0.5877162218093872\n",
      "5 15 0.6243666410446167\n",
      "5 16 0.6835907697677612\n",
      "5 17 0.6053834557533264\n",
      "5 18 0.6039389371871948\n",
      "5 19 0.6230868101119995\n",
      "5 20 0.6025125980377197\n",
      "5 21 0.5800992846488953\n",
      "5 22 0.6003945469856262\n",
      "5 23 0.7406571507453918\n",
      "6 0 0.6227062344551086\n",
      "6 1 0.7297964692115784\n",
      "6 2 0.6237490773200989\n",
      "6 3 0.6848790645599365\n",
      "6 4 0.6038703918457031\n",
      "6 5 0.5827176570892334\n",
      "6 6 0.7289355397224426\n",
      "6 7 0.6433957815170288\n",
      "6 8 0.6037999391555786\n",
      "6 9 0.7474661469459534\n",
      "6 10 0.6245041489601135\n",
      "6 11 0.663344144821167\n",
      "6 12 0.5857158899307251\n",
      "6 13 0.7046356201171875\n",
      "6 14 0.6247661113739014\n",
      "6 15 0.6833204627037048\n",
      "6 16 0.6057218909263611\n",
      "6 17 0.6043407917022705\n",
      "6 18 0.6234265565872192\n",
      "6 19 0.6644364595413208\n",
      "6 20 0.6234332919120789\n",
      "6 21 0.6438400149345398\n",
      "6 22 0.68463534116745\n",
      "6 23 0.5907483696937561\n",
      "7 0 0.5815587639808655\n",
      "7 1 0.5796511173248291\n",
      "7 2 0.7106846570968628\n",
      "7 3 0.686980664730072\n",
      "7 4 0.6435052156448364\n",
      "7 5 0.6024262309074402\n",
      "7 6 0.6649608016014099\n",
      "7 7 0.6649406552314758\n",
      "7 8 0.6642993092536926\n",
      "7 9 0.6438708901405334\n",
      "7 10 0.7248896360397339\n",
      "7 11 0.6053135395050049\n",
      "7 12 0.6639682054519653\n",
      "7 13 0.644022524356842\n",
      "7 14 0.6243680119514465\n",
      "7 15 0.6835835576057434\n",
      "7 16 0.7218368649482727\n",
      "7 17 0.5336271524429321\n",
      "7 18 0.683898389339447\n",
      "7 19 0.6047343015670776\n",
      "7 20 0.6846392750740051\n",
      "7 21 0.5854803323745728\n",
      "7 22 0.6844319105148315\n",
      "7 23 0.6185088753700256\n",
      "8 0 0.6232725977897644\n",
      "8 1 0.6025964617729187\n",
      "8 2 0.6023011207580566\n",
      "8 3 0.622431755065918\n",
      "8 4 0.7092397212982178\n",
      "8 5 0.6646378636360168\n",
      "8 6 0.6441656351089478\n",
      "8 7 0.5619819164276123\n",
      "8 8 0.5584794878959656\n",
      "8 9 0.6443789005279541\n",
      "8 10 0.7781590223312378\n",
      "8 11 0.6646057963371277\n",
      "8 12 0.7658492922782898\n",
      "8 13 0.6442769765853882\n",
      "8 14 0.6062111854553223\n",
      "8 15 0.6244717836380005\n",
      "8 16 0.6831409335136414\n",
      "8 17 0.605258584022522\n",
      "8 18 0.723137617111206\n",
      "8 19 0.6817831993103027\n",
      "8 20 0.5893071293830872\n",
      "8 21 0.6633961200714111\n",
      "8 22 0.5866341590881348\n",
      "8 23 0.6740350723266602\n",
      "9 0 0.6632307171821594\n",
      "9 1 0.6247797012329102\n",
      "9 2 0.5654483437538147\n",
      "9 3 0.6850694417953491\n",
      "9 4 0.7041866183280945\n",
      "9 5 0.6244638562202454\n",
      "9 6 0.6246708035469055\n",
      "9 7 0.6043357253074646\n",
      "9 8 0.6437346935272217\n",
      "9 9 0.6644209623336792\n",
      "9 10 0.6841351389884949\n",
      "9 11 0.6436700820922852\n",
      "9 12 0.6242080926895142\n",
      "9 13 0.6440062522888184\n",
      "9 14 0.643771767616272\n",
      "9 15 0.7239987254142761\n",
      "9 16 0.6439245939254761\n",
      "9 17 0.5868618488311768\n",
      "9 18 0.7037168741226196\n",
      "9 19 0.6054593920707703\n",
      "9 20 0.7027014493942261\n",
      "9 21 0.5299026966094971\n",
      "9 22 0.7060806751251221\n",
      "9 23 0.6738246083259583\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        y_pred = model(inputs)\n",
    "        \n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17_p38",
   "language": "python",
   "name": "pytorch17_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

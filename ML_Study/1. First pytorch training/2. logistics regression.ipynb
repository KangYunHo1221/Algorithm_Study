{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import pdb\n",
    "from torch import tensor\n",
    "from torch import sigmoid\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "y_data = tensor([[0.0],[0.0],[1.0],[1.0]])\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x): #thnk black box\n",
    "        y_pred = sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    \n",
    "model = Model()  #creat empty model\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction = 'mean')   # Mean Sqr Err\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)  #learning rate #sgd = stochastic gradient decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ... Loss: 0.897545576095581 \n",
      "Epoch: 2 ... Loss: 0.8848896622657776 \n",
      "Epoch: 3 ... Loss: 0.8726224899291992 \n",
      "Epoch: 4 ... Loss: 0.8607387542724609 \n",
      "Epoch: 5 ... Loss: 0.8492330312728882 \n",
      "Epoch: 6 ... Loss: 0.8380992412567139 \n",
      "Epoch: 7 ... Loss: 0.8273311257362366 \n",
      "Epoch: 8 ... Loss: 0.8169218301773071 \n",
      "Epoch: 9 ... Loss: 0.806864321231842 \n",
      "Epoch: 10 ... Loss: 0.7971510887145996 \n",
      "Epoch: 11 ... Loss: 0.7877746820449829 \n",
      "Epoch: 12 ... Loss: 0.7787271738052368 \n",
      "Epoch: 13 ... Loss: 0.7700004577636719 \n",
      "Epoch: 14 ... Loss: 0.7615864276885986 \n",
      "Epoch: 15 ... Loss: 0.7534767389297485 \n",
      "Epoch: 16 ... Loss: 0.7456629872322083 \n",
      "Epoch: 17 ... Loss: 0.7381367683410645 \n",
      "Epoch: 18 ... Loss: 0.7308894991874695 \n",
      "Epoch: 19 ... Loss: 0.7239128351211548 \n",
      "Epoch: 20 ... Loss: 0.7171982526779175 \n",
      "Epoch: 21 ... Loss: 0.710737407207489 \n",
      "Epoch: 22 ... Loss: 0.704521894454956 \n",
      "Epoch: 23 ... Loss: 0.6985436677932739 \n",
      "Epoch: 24 ... Loss: 0.6927945017814636 \n",
      "Epoch: 25 ... Loss: 0.68726646900177 \n",
      "Epoch: 26 ... Loss: 0.681951642036438 \n",
      "Epoch: 27 ... Loss: 0.6768423914909363 \n",
      "Epoch: 28 ... Loss: 0.671931266784668 \n",
      "Epoch: 29 ... Loss: 0.6672108769416809 \n",
      "Epoch: 30 ... Loss: 0.6626739501953125 \n",
      "Epoch: 31 ... Loss: 0.6583136916160583 \n",
      "Epoch: 32 ... Loss: 0.654123067855835 \n",
      "Epoch: 33 ... Loss: 0.6500958204269409 \n",
      "Epoch: 34 ... Loss: 0.6462253928184509 \n",
      "Epoch: 35 ... Loss: 0.6425054669380188 \n",
      "Epoch: 36 ... Loss: 0.6389302015304565 \n",
      "Epoch: 37 ... Loss: 0.6354937553405762 \n",
      "Epoch: 38 ... Loss: 0.6321905255317688 \n",
      "Epoch: 39 ... Loss: 0.6290151476860046 \n",
      "Epoch: 40 ... Loss: 0.6259622573852539 \n",
      "Epoch: 41 ... Loss: 0.623026967048645 \n",
      "Epoch: 42 ... Loss: 0.6202044486999512 \n",
      "Epoch: 43 ... Loss: 0.6174899339675903 \n",
      "Epoch: 44 ... Loss: 0.6148790121078491 \n",
      "Epoch: 45 ... Loss: 0.6123673319816589 \n",
      "Epoch: 46 ... Loss: 0.6099507808685303 \n",
      "Epoch: 47 ... Loss: 0.6076253652572632 \n",
      "Epoch: 48 ... Loss: 0.6053873300552368 \n",
      "Epoch: 49 ... Loss: 0.6032328009605408 \n",
      "Epoch: 50 ... Loss: 0.6011584997177124 \n",
      "Epoch: 51 ... Loss: 0.5991609692573547 \n",
      "Epoch: 52 ... Loss: 0.5972369313240051 \n",
      "Epoch: 53 ... Loss: 0.5953834056854248 \n",
      "Epoch: 54 ... Loss: 0.5935971736907959 \n",
      "Epoch: 55 ... Loss: 0.5918756723403931 \n",
      "Epoch: 56 ... Loss: 0.5902160406112671 \n",
      "Epoch: 57 ... Loss: 0.5886156558990479 \n",
      "Epoch: 58 ... Loss: 0.5870721340179443 \n",
      "Epoch: 59 ... Loss: 0.5855829119682312 \n",
      "Epoch: 60 ... Loss: 0.5841459035873413 \n",
      "Epoch: 61 ... Loss: 0.5827587246894836 \n",
      "Epoch: 62 ... Loss: 0.5814193487167358 \n",
      "Epoch: 63 ... Loss: 0.5801258683204651 \n",
      "Epoch: 64 ... Loss: 0.5788761973381042 \n",
      "Epoch: 65 ... Loss: 0.5776685476303101 \n",
      "Epoch: 66 ... Loss: 0.5765012502670288 \n",
      "Epoch: 67 ... Loss: 0.575372576713562 \n",
      "Epoch: 68 ... Loss: 0.5742807984352112 \n",
      "Epoch: 69 ... Loss: 0.5732246041297913 \n",
      "Epoch: 70 ... Loss: 0.5722023844718933 \n",
      "Epoch: 71 ... Loss: 0.5712127685546875 \n",
      "Epoch: 72 ... Loss: 0.5702543258666992 \n",
      "Epoch: 73 ... Loss: 0.569325864315033 \n",
      "Epoch: 74 ... Loss: 0.5684261322021484 \n",
      "Epoch: 75 ... Loss: 0.5675538778305054 \n",
      "Epoch: 76 ... Loss: 0.5667080879211426 \n",
      "Epoch: 77 ... Loss: 0.5658875703811646 \n",
      "Epoch: 78 ... Loss: 0.5650913715362549 \n",
      "Epoch: 79 ... Loss: 0.5643184185028076 \n",
      "Epoch: 80 ... Loss: 0.5635679960250854 \n",
      "Epoch: 81 ... Loss: 0.5628387928009033 \n",
      "Epoch: 82 ... Loss: 0.5621302723884583 \n",
      "Epoch: 83 ... Loss: 0.5614414811134338 \n",
      "Epoch: 84 ... Loss: 0.5607715845108032 \n",
      "Epoch: 85 ... Loss: 0.5601199269294739 \n",
      "Epoch: 86 ... Loss: 0.5594857931137085 \n",
      "Epoch: 87 ... Loss: 0.5588683485984802 \n",
      "Epoch: 88 ... Loss: 0.5582670569419861 \n",
      "Epoch: 89 ... Loss: 0.557681143283844 \n",
      "Epoch: 90 ... Loss: 0.5571101307868958 \n",
      "Epoch: 91 ... Loss: 0.5565533638000488 \n",
      "Epoch: 92 ... Loss: 0.5560103058815002 \n",
      "Epoch: 93 ... Loss: 0.5554803013801575 \n",
      "Epoch: 94 ... Loss: 0.5549631118774414 \n",
      "Epoch: 95 ... Loss: 0.5544579029083252 \n",
      "Epoch: 96 ... Loss: 0.5539644360542297 \n",
      "Epoch: 97 ... Loss: 0.5534821152687073 \n",
      "Epoch: 98 ... Loss: 0.5530106425285339 \n",
      "Epoch: 99 ... Loss: 0.5525494813919067 \n",
      "Epoch: 100 ... Loss: 0.5520983338356018 \n",
      "Epoch: 101 ... Loss: 0.5516567230224609 \n",
      "Epoch: 102 ... Loss: 0.5512242913246155 \n",
      "Epoch: 103 ... Loss: 0.5508007407188416 \n",
      "Epoch: 104 ... Loss: 0.5503857135772705 \n",
      "Epoch: 105 ... Loss: 0.5499788522720337 \n",
      "Epoch: 106 ... Loss: 0.5495799779891968 \n",
      "Epoch: 107 ... Loss: 0.549188494682312 \n",
      "Epoch: 108 ... Loss: 0.5488044023513794 \n",
      "Epoch: 109 ... Loss: 0.5484273433685303 \n",
      "Epoch: 110 ... Loss: 0.548056960105896 \n",
      "Epoch: 111 ... Loss: 0.547693133354187 \n",
      "Epoch: 112 ... Loss: 0.5473355054855347 \n",
      "Epoch: 113 ... Loss: 0.5469840168952942 \n",
      "Epoch: 114 ... Loss: 0.5466382503509521 \n",
      "Epoch: 115 ... Loss: 0.5462979674339294 \n",
      "Epoch: 116 ... Loss: 0.5459631681442261 \n",
      "Epoch: 117 ... Loss: 0.5456336140632629 \n",
      "Epoch: 118 ... Loss: 0.5453089475631714 \n",
      "Epoch: 119 ... Loss: 0.5449890494346619 \n",
      "Epoch: 120 ... Loss: 0.5446738600730896 \n",
      "Epoch: 121 ... Loss: 0.5443631410598755 \n",
      "Epoch: 122 ... Loss: 0.5440566539764404 \n",
      "Epoch: 123 ... Loss: 0.5437543392181396 \n",
      "Epoch: 124 ... Loss: 0.5434560179710388 \n",
      "Epoch: 125 ... Loss: 0.5431615114212036 \n",
      "Epoch: 126 ... Loss: 0.5428707599639893 \n",
      "Epoch: 127 ... Loss: 0.5425835251808167 \n",
      "Epoch: 128 ... Loss: 0.542299747467041 \n",
      "Epoch: 129 ... Loss: 0.5420193672180176 \n",
      "Epoch: 130 ... Loss: 0.5417421460151672 \n",
      "Epoch: 131 ... Loss: 0.5414679050445557 \n",
      "Epoch: 132 ... Loss: 0.5411967635154724 \n",
      "Epoch: 133 ... Loss: 0.5409284234046936 \n",
      "Epoch: 134 ... Loss: 0.5406630039215088 \n",
      "Epoch: 135 ... Loss: 0.5404000878334045 \n",
      "Epoch: 136 ... Loss: 0.5401398539543152 \n",
      "Epoch: 137 ... Loss: 0.5398821234703064 \n",
      "Epoch: 138 ... Loss: 0.5396268367767334 \n",
      "Epoch: 139 ... Loss: 0.5393738150596619 \n",
      "Epoch: 140 ... Loss: 0.5391230583190918 \n",
      "Epoch: 141 ... Loss: 0.5388744473457336 \n",
      "Epoch: 142 ... Loss: 0.5386279225349426 \n",
      "Epoch: 143 ... Loss: 0.538383424282074 \n",
      "Epoch: 144 ... Loss: 0.5381408929824829 \n",
      "Epoch: 145 ... Loss: 0.5379002690315247 \n",
      "Epoch: 146 ... Loss: 0.5376614332199097 \n",
      "Epoch: 147 ... Loss: 0.5374243855476379 \n",
      "Epoch: 148 ... Loss: 0.5371890068054199 \n",
      "Epoch: 149 ... Loss: 0.5369553565979004 \n",
      "Epoch: 150 ... Loss: 0.536723256111145 \n",
      "Epoch: 151 ... Loss: 0.536492645740509 \n",
      "Epoch: 152 ... Loss: 0.5362635850906372 \n",
      "Epoch: 153 ... Loss: 0.5360358953475952 \n",
      "Epoch: 154 ... Loss: 0.5358096361160278 \n",
      "Epoch: 155 ... Loss: 0.5355848073959351 \n",
      "Epoch: 156 ... Loss: 0.5353611707687378 \n",
      "Epoch: 157 ... Loss: 0.5351388454437256 \n",
      "Epoch: 158 ... Loss: 0.5349177718162537 \n",
      "Epoch: 159 ... Loss: 0.5346977710723877 \n",
      "Epoch: 160 ... Loss: 0.534479022026062 \n",
      "Epoch: 161 ... Loss: 0.5342614054679871 \n",
      "Epoch: 162 ... Loss: 0.5340448021888733 \n",
      "Epoch: 163 ... Loss: 0.5338292717933655 \n",
      "Epoch: 164 ... Loss: 0.5336147546768188 \n",
      "Epoch: 165 ... Loss: 0.5334011316299438 \n",
      "Epoch: 166 ... Loss: 0.5331885814666748 \n",
      "Epoch: 167 ... Loss: 0.5329768061637878 \n",
      "Epoch: 168 ... Loss: 0.5327660441398621 \n",
      "Epoch: 169 ... Loss: 0.5325560569763184 \n",
      "Epoch: 170 ... Loss: 0.5323469638824463 \n",
      "Epoch: 171 ... Loss: 0.5321387052536011 \n",
      "Epoch: 172 ... Loss: 0.5319311618804932 \n",
      "Epoch: 173 ... Loss: 0.5317244529724121 \n",
      "Epoch: 174 ... Loss: 0.5315184593200684 \n",
      "Epoch: 175 ... Loss: 0.5313131809234619 \n",
      "Epoch: 176 ... Loss: 0.5311086177825928 \n",
      "Epoch: 177 ... Loss: 0.5309047698974609 \n",
      "Epoch: 178 ... Loss: 0.5307015180587769 \n",
      "Epoch: 179 ... Loss: 0.5304989814758301 \n",
      "Epoch: 180 ... Loss: 0.5302969813346863 \n",
      "Epoch: 181 ... Loss: 0.5300955772399902 \n",
      "Epoch: 182 ... Loss: 0.5298948287963867 \n",
      "Epoch: 183 ... Loss: 0.5296946167945862 \n",
      "Epoch: 184 ... Loss: 0.5294950008392334 \n",
      "Epoch: 185 ... Loss: 0.5292959213256836 \n",
      "Epoch: 186 ... Loss: 0.5290973782539368 \n",
      "Epoch: 187 ... Loss: 0.5288993716239929 \n",
      "Epoch: 188 ... Loss: 0.5287018418312073 \n",
      "Epoch: 189 ... Loss: 0.5285047292709351 \n",
      "Epoch: 190 ... Loss: 0.5283082127571106 \n",
      "Epoch: 191 ... Loss: 0.5281120538711548 \n",
      "Epoch: 192 ... Loss: 0.527916431427002 \n",
      "Epoch: 193 ... Loss: 0.5277211666107178 \n",
      "Epoch: 194 ... Loss: 0.5275263786315918 \n",
      "Epoch: 195 ... Loss: 0.527332067489624 \n",
      "Epoch: 196 ... Loss: 0.5271381139755249 \n",
      "Epoch: 197 ... Loss: 0.5269445180892944 \n",
      "Epoch: 198 ... Loss: 0.5267513394355774 \n",
      "Epoch: 199 ... Loss: 0.5265585780143738 \n",
      "Epoch: 200 ... Loss: 0.5263661742210388 \n",
      "Epoch: 201 ... Loss: 0.5261741280555725 \n",
      "Epoch: 202 ... Loss: 0.5259824395179749 \n",
      "Epoch: 203 ... Loss: 0.5257910490036011 \n",
      "Epoch: 204 ... Loss: 0.5256000757217407 \n",
      "Epoch: 205 ... Loss: 0.5254093408584595 \n",
      "Epoch: 206 ... Loss: 0.5252190828323364 \n",
      "Epoch: 207 ... Loss: 0.5250290036201477 \n",
      "Epoch: 208 ... Loss: 0.5248393416404724 \n",
      "Epoch: 209 ... Loss: 0.5246498584747314 \n",
      "Epoch: 210 ... Loss: 0.5244607925415039 \n",
      "Epoch: 211 ... Loss: 0.5242719650268555 \n",
      "Epoch: 212 ... Loss: 0.5240834355354309 \n",
      "Epoch: 213 ... Loss: 0.5238951444625854 \n",
      "Epoch: 214 ... Loss: 0.5237072110176086 \n",
      "Epoch: 215 ... Loss: 0.5235194563865662 \n",
      "Epoch: 216 ... Loss: 0.5233320593833923 \n",
      "Epoch: 217 ... Loss: 0.5231448411941528 \n",
      "Epoch: 218 ... Loss: 0.522957980632782 \n",
      "Epoch: 219 ... Loss: 0.5227713584899902 \n",
      "Epoch: 220 ... Loss: 0.5225847959518433 \n",
      "Epoch: 221 ... Loss: 0.5223986506462097 \n",
      "Epoch: 222 ... Loss: 0.5222127437591553 \n",
      "Epoch: 223 ... Loss: 0.5220270156860352 \n",
      "Epoch: 224 ... Loss: 0.5218416452407837 \n",
      "Epoch: 225 ... Loss: 0.5216563940048218 \n",
      "Epoch: 226 ... Loss: 0.5214713215827942 \n",
      "Epoch: 227 ... Loss: 0.5212865471839905 \n",
      "Epoch: 228 ... Loss: 0.5211019515991211 \n",
      "Epoch: 229 ... Loss: 0.5209175944328308 \n",
      "Epoch: 230 ... Loss: 0.5207334160804749 \n",
      "Epoch: 231 ... Loss: 0.520549476146698 \n",
      "Epoch: 232 ... Loss: 0.5203657150268555 \n",
      "Epoch: 233 ... Loss: 0.5201821327209473 \n",
      "Epoch: 234 ... Loss: 0.5199989080429077 \n",
      "Epoch: 235 ... Loss: 0.5198156833648682 \n",
      "Epoch: 236 ... Loss: 0.5196327567100525 \n",
      "Epoch: 237 ... Loss: 0.5194500088691711 \n",
      "Epoch: 238 ... Loss: 0.5192674398422241 \n",
      "Epoch: 239 ... Loss: 0.5190851092338562 \n",
      "Epoch: 240 ... Loss: 0.5189028382301331 \n",
      "Epoch: 241 ... Loss: 0.518720805644989 \n",
      "Epoch: 242 ... Loss: 0.5185390114784241 \n",
      "Epoch: 243 ... Loss: 0.5183573365211487 \n",
      "Epoch: 244 ... Loss: 0.5181758999824524 \n",
      "Epoch: 245 ... Loss: 0.5179945826530457 \n",
      "Epoch: 246 ... Loss: 0.5178134441375732 \n",
      "Epoch: 247 ... Loss: 0.5176324844360352 \n",
      "Epoch: 248 ... Loss: 0.5174516439437866 \n",
      "Epoch: 249 ... Loss: 0.517271101474762 \n",
      "Epoch: 250 ... Loss: 0.5170905590057373 \n",
      "Epoch: 251 ... Loss: 0.5169103145599365 \n",
      "Epoch: 252 ... Loss: 0.5167301297187805 \n",
      "Epoch: 253 ... Loss: 0.5165501832962036 \n",
      "Epoch: 254 ... Loss: 0.516370415687561 \n",
      "Epoch: 255 ... Loss: 0.516190767288208 \n",
      "Epoch: 256 ... Loss: 0.5160112977027893 \n",
      "Epoch: 257 ... Loss: 0.5158318877220154 \n",
      "Epoch: 258 ... Loss: 0.5156527757644653 \n",
      "Epoch: 259 ... Loss: 0.5154737234115601 \n",
      "Epoch: 260 ... Loss: 0.5152948498725891 \n",
      "Epoch: 261 ... Loss: 0.5151160955429077 \n",
      "Epoch: 262 ... Loss: 0.5149375200271606 \n",
      "Epoch: 263 ... Loss: 0.5147591233253479 \n",
      "Epoch: 264 ... Loss: 0.5145808458328247 \n",
      "Epoch: 265 ... Loss: 0.5144026875495911 \n",
      "Epoch: 266 ... Loss: 0.5142247080802917 \n",
      "Epoch: 267 ... Loss: 0.5140469074249268 \n",
      "Epoch: 268 ... Loss: 0.5138691663742065 \n",
      "Epoch: 269 ... Loss: 0.5136916637420654 \n",
      "Epoch: 270 ... Loss: 0.5135142207145691 \n",
      "Epoch: 271 ... Loss: 0.5133369565010071 \n",
      "Epoch: 272 ... Loss: 0.5131598711013794 \n",
      "Epoch: 273 ... Loss: 0.5129828453063965 \n",
      "Epoch: 274 ... Loss: 0.5128061175346375 \n",
      "Epoch: 275 ... Loss: 0.5126292705535889 \n",
      "Epoch: 276 ... Loss: 0.5124527812004089 \n",
      "Epoch: 277 ... Loss: 0.5122763514518738 \n",
      "Epoch: 278 ... Loss: 0.5121000409126282 \n",
      "Epoch: 279 ... Loss: 0.5119239091873169 \n",
      "Epoch: 280 ... Loss: 0.5117478370666504 \n",
      "Epoch: 281 ... Loss: 0.5115719437599182 \n",
      "Epoch: 282 ... Loss: 0.5113961696624756 \n",
      "Epoch: 283 ... Loss: 0.5112205743789673 \n",
      "Epoch: 284 ... Loss: 0.5110450983047485 \n",
      "Epoch: 285 ... Loss: 0.5108698010444641 \n",
      "Epoch: 286 ... Loss: 0.5106945037841797 \n",
      "Epoch: 287 ... Loss: 0.5105194449424744 \n",
      "Epoch: 288 ... Loss: 0.5103445649147034 \n",
      "Epoch: 289 ... Loss: 0.5101696252822876 \n",
      "Epoch: 290 ... Loss: 0.5099949240684509 \n",
      "Epoch: 291 ... Loss: 0.5098204016685486 \n",
      "Epoch: 292 ... Loss: 0.509645938873291 \n",
      "Epoch: 293 ... Loss: 0.509471595287323 \n",
      "Epoch: 294 ... Loss: 0.5092974901199341 \n",
      "Epoch: 295 ... Loss: 0.5091234445571899 \n",
      "Epoch: 296 ... Loss: 0.5089494585990906 \n",
      "Epoch: 297 ... Loss: 0.5087756514549255 \n",
      "Epoch: 298 ... Loss: 0.50860196352005 \n",
      "Epoch: 299 ... Loss: 0.5084284543991089 \n",
      "Epoch: 300 ... Loss: 0.5082550048828125 \n",
      "Epoch: 301 ... Loss: 0.5080817341804504 \n",
      "Epoch: 302 ... Loss: 0.5079085230827332 \n",
      "Epoch: 303 ... Loss: 0.5077354907989502 \n",
      "Epoch: 304 ... Loss: 0.5075625777244568 \n",
      "Epoch: 305 ... Loss: 0.5073897838592529 \n",
      "Epoch: 306 ... Loss: 0.5072171092033386 \n",
      "Epoch: 307 ... Loss: 0.5070445537567139 \n",
      "Epoch: 308 ... Loss: 0.5068721175193787 \n",
      "Epoch: 309 ... Loss: 0.506699800491333 \n",
      "Epoch: 310 ... Loss: 0.5065276026725769 \n",
      "Epoch: 311 ... Loss: 0.5063555240631104 \n",
      "Epoch: 312 ... Loss: 0.5061835646629333 \n",
      "Epoch: 313 ... Loss: 0.5060117840766907 \n",
      "Epoch: 314 ... Loss: 0.5058401226997375 \n",
      "Epoch: 315 ... Loss: 0.5056685209274292 \n",
      "Epoch: 316 ... Loss: 0.5054970979690552 \n",
      "Epoch: 317 ... Loss: 0.5053257346153259 \n",
      "Epoch: 318 ... Loss: 0.505154550075531 \n",
      "Epoch: 319 ... Loss: 0.5049833655357361 \n",
      "Epoch: 320 ... Loss: 0.5048123598098755 \n",
      "Epoch: 321 ... Loss: 0.5046415328979492 \n",
      "Epoch: 322 ... Loss: 0.5044708251953125 \n",
      "Epoch: 323 ... Loss: 0.5043002367019653 \n",
      "Epoch: 324 ... Loss: 0.5041297078132629 \n",
      "Epoch: 325 ... Loss: 0.5039593577384949 \n",
      "Epoch: 326 ... Loss: 0.5037890672683716 \n",
      "Epoch: 327 ... Loss: 0.5036188960075378 \n",
      "Epoch: 328 ... Loss: 0.5034489035606384 \n",
      "Epoch: 329 ... Loss: 0.5032790303230286 \n",
      "Epoch: 330 ... Loss: 0.5031092166900635 \n",
      "Epoch: 331 ... Loss: 0.5029395818710327 \n",
      "Epoch: 332 ... Loss: 0.5027700662612915 \n",
      "Epoch: 333 ... Loss: 0.5026005506515503 \n",
      "Epoch: 334 ... Loss: 0.5024312138557434 \n",
      "Epoch: 335 ... Loss: 0.5022620558738708 \n",
      "Epoch: 336 ... Loss: 0.5020929574966431 \n",
      "Epoch: 337 ... Loss: 0.5019239783287048 \n",
      "Epoch: 338 ... Loss: 0.5017551779747009 \n",
      "Epoch: 339 ... Loss: 0.5015864372253418 \n",
      "Epoch: 340 ... Loss: 0.5014177560806274 \n",
      "Epoch: 341 ... Loss: 0.5012493133544922 \n",
      "Epoch: 342 ... Loss: 0.5010809302330017 \n",
      "Epoch: 343 ... Loss: 0.5009126663208008 \n",
      "Epoch: 344 ... Loss: 0.5007445216178894 \n",
      "Epoch: 345 ... Loss: 0.5005764365196228 \n",
      "Epoch: 346 ... Loss: 0.5004085898399353 \n",
      "Epoch: 347 ... Loss: 0.500240683555603 \n",
      "Epoch: 348 ... Loss: 0.5000730156898499 \n",
      "Epoch: 349 ... Loss: 0.49990546703338623 \n",
      "Epoch: 350 ... Loss: 0.49973803758621216 \n",
      "Epoch: 351 ... Loss: 0.4995706081390381 \n",
      "Epoch: 352 ... Loss: 0.4994034469127655 \n",
      "Epoch: 353 ... Loss: 0.49923625588417053 \n",
      "Epoch: 354 ... Loss: 0.4990692734718323 \n",
      "Epoch: 355 ... Loss: 0.4989023804664612 \n",
      "Epoch: 356 ... Loss: 0.49873557686805725 \n",
      "Epoch: 357 ... Loss: 0.49856895208358765 \n",
      "Epoch: 358 ... Loss: 0.4984024167060852 \n",
      "Epoch: 359 ... Loss: 0.49823594093322754 \n",
      "Epoch: 360 ... Loss: 0.4980696141719818 \n",
      "Epoch: 361 ... Loss: 0.49790340662002563 \n",
      "Epoch: 362 ... Loss: 0.497737318277359 \n",
      "Epoch: 363 ... Loss: 0.49757134914398193 \n",
      "Epoch: 364 ... Loss: 0.497405469417572 \n",
      "Epoch: 365 ... Loss: 0.49723973870277405 \n",
      "Epoch: 366 ... Loss: 0.49707409739494324 \n",
      "Epoch: 367 ... Loss: 0.4969085156917572 \n",
      "Epoch: 368 ... Loss: 0.4967430830001831 \n",
      "Epoch: 369 ... Loss: 0.49657779932022095 \n",
      "Epoch: 370 ... Loss: 0.49641263484954834 \n",
      "Epoch: 371 ... Loss: 0.4962475597858429 \n",
      "Epoch: 372 ... Loss: 0.49608245491981506 \n",
      "Epoch: 373 ... Loss: 0.4959176778793335 \n",
      "Epoch: 374 ... Loss: 0.49575290083885193 \n",
      "Epoch: 375 ... Loss: 0.4955882728099823 \n",
      "Epoch: 376 ... Loss: 0.49542370438575745 \n",
      "Epoch: 377 ... Loss: 0.4952593445777893 \n",
      "Epoch: 378 ... Loss: 0.49509504437446594 \n",
      "Epoch: 379 ... Loss: 0.49493083357810974 \n",
      "Epoch: 380 ... Loss: 0.4947667717933655 \n",
      "Epoch: 381 ... Loss: 0.494602769613266 \n",
      "Epoch: 382 ... Loss: 0.4944389760494232 \n",
      "Epoch: 383 ... Loss: 0.49427515268325806 \n",
      "Epoch: 384 ... Loss: 0.494111567735672 \n",
      "Epoch: 385 ... Loss: 0.4939480125904083 \n",
      "Epoch: 386 ... Loss: 0.4937845766544342 \n",
      "Epoch: 387 ... Loss: 0.4936213195323944 \n",
      "Epoch: 388 ... Loss: 0.4934580624103546 \n",
      "Epoch: 389 ... Loss: 0.49329498410224915 \n",
      "Epoch: 390 ... Loss: 0.49313199520111084 \n",
      "Epoch: 391 ... Loss: 0.4929691553115845 \n",
      "Epoch: 392 ... Loss: 0.4928063750267029 \n",
      "Epoch: 393 ... Loss: 0.49264365434646606 \n",
      "Epoch: 394 ... Loss: 0.49248117208480835 \n",
      "Epoch: 395 ... Loss: 0.49231868982315063 \n",
      "Epoch: 396 ... Loss: 0.49215641617774963 \n",
      "Epoch: 397 ... Loss: 0.4919942319393158 \n",
      "Epoch: 398 ... Loss: 0.49183204770088196 \n",
      "Epoch: 399 ... Loss: 0.4916701018810272 \n",
      "Epoch: 400 ... Loss: 0.49150821566581726 \n",
      "Epoch: 401 ... Loss: 0.49134647846221924 \n",
      "Epoch: 402 ... Loss: 0.4911847710609436 \n",
      "Epoch: 403 ... Loss: 0.4910232126712799 \n",
      "Epoch: 404 ... Loss: 0.49086180329322815 \n",
      "Epoch: 405 ... Loss: 0.49070051312446594 \n",
      "Epoch: 406 ... Loss: 0.49053916335105896 \n",
      "Epoch: 407 ... Loss: 0.4903780519962311 \n",
      "Epoch: 408 ... Loss: 0.4902171194553375 \n",
      "Epoch: 409 ... Loss: 0.4900561571121216 \n",
      "Epoch: 410 ... Loss: 0.48989537358283997 \n",
      "Epoch: 411 ... Loss: 0.4897347092628479 \n",
      "Epoch: 412 ... Loss: 0.4895741045475006 \n",
      "Epoch: 413 ... Loss: 0.48941361904144287 \n",
      "Epoch: 414 ... Loss: 0.48925331234931946 \n",
      "Epoch: 415 ... Loss: 0.48909300565719604 \n",
      "Epoch: 416 ... Loss: 0.4889328181743622 \n",
      "Epoch: 417 ... Loss: 0.48877277970314026 \n",
      "Epoch: 418 ... Loss: 0.4886128902435303 \n",
      "Epoch: 419 ... Loss: 0.4884530305862427 \n",
      "Epoch: 420 ... Loss: 0.48829329013824463 \n",
      "Epoch: 421 ... Loss: 0.4881336987018585 \n",
      "Epoch: 422 ... Loss: 0.4879741966724396 \n",
      "Epoch: 423 ... Loss: 0.4878148138523102 \n",
      "Epoch: 424 ... Loss: 0.48765549063682556 \n",
      "Epoch: 425 ... Loss: 0.4874962866306305 \n",
      "Epoch: 426 ... Loss: 0.4873371720314026 \n",
      "Epoch: 427 ... Loss: 0.487178236246109 \n",
      "Epoch: 428 ... Loss: 0.4870193600654602 \n",
      "Epoch: 429 ... Loss: 0.4868605434894562 \n",
      "Epoch: 430 ... Loss: 0.48670193552970886 \n",
      "Epoch: 431 ... Loss: 0.48654329776763916 \n",
      "Epoch: 432 ... Loss: 0.48638492822647095 \n",
      "Epoch: 433 ... Loss: 0.4862266182899475 \n",
      "Epoch: 434 ... Loss: 0.4860683083534241 \n",
      "Epoch: 435 ... Loss: 0.48591017723083496 \n",
      "Epoch: 436 ... Loss: 0.4857522249221802 \n",
      "Epoch: 437 ... Loss: 0.4855942726135254 \n",
      "Epoch: 438 ... Loss: 0.48543646931648254 \n",
      "Epoch: 439 ... Loss: 0.48527875542640686 \n",
      "Epoch: 440 ... Loss: 0.4851211905479431 \n",
      "Epoch: 441 ... Loss: 0.48496365547180176 \n",
      "Epoch: 442 ... Loss: 0.48480623960494995 \n",
      "Epoch: 443 ... Loss: 0.4846489429473877 \n",
      "Epoch: 444 ... Loss: 0.4844917953014374 \n",
      "Epoch: 445 ... Loss: 0.4843347370624542 \n",
      "Epoch: 446 ... Loss: 0.48417776823043823 \n",
      "Epoch: 447 ... Loss: 0.484020859003067 \n",
      "Epoch: 448 ... Loss: 0.48386409878730774 \n",
      "Epoch: 449 ... Loss: 0.4837074279785156 \n",
      "Epoch: 450 ... Loss: 0.48355090618133545 \n",
      "Epoch: 451 ... Loss: 0.48339444398880005 \n",
      "Epoch: 452 ... Loss: 0.483238160610199 \n",
      "Epoch: 453 ... Loss: 0.4830818474292755 \n",
      "Epoch: 454 ... Loss: 0.4829257130622864 \n",
      "Epoch: 455 ... Loss: 0.4827696979045868 \n",
      "Epoch: 456 ... Loss: 0.48261377215385437 \n",
      "Epoch: 457 ... Loss: 0.4824579656124115 \n",
      "Epoch: 458 ... Loss: 0.4823022186756134 \n",
      "Epoch: 459 ... Loss: 0.48214656114578247 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460 ... Loss: 0.48199111223220825 \n",
      "Epoch: 461 ... Loss: 0.4818357229232788 \n",
      "Epoch: 462 ... Loss: 0.48168039321899414 \n",
      "Epoch: 463 ... Loss: 0.48152515292167664 \n",
      "Epoch: 464 ... Loss: 0.48137009143829346 \n",
      "Epoch: 465 ... Loss: 0.48121505975723267 \n",
      "Epoch: 466 ... Loss: 0.4810602366924286 \n",
      "Epoch: 467 ... Loss: 0.4809054136276245 \n",
      "Epoch: 468 ... Loss: 0.4807507395744324 \n",
      "Epoch: 469 ... Loss: 0.480596125125885 \n",
      "Epoch: 470 ... Loss: 0.4804416298866272 \n",
      "Epoch: 471 ... Loss: 0.48028722405433655 \n",
      "Epoch: 472 ... Loss: 0.4801330268383026 \n",
      "Epoch: 473 ... Loss: 0.4799787700176239 \n",
      "Epoch: 474 ... Loss: 0.4798247218132019 \n",
      "Epoch: 475 ... Loss: 0.47967076301574707 \n",
      "Epoch: 476 ... Loss: 0.4795168340206146 \n",
      "Epoch: 477 ... Loss: 0.4793631434440613 \n",
      "Epoch: 478 ... Loss: 0.47920945286750793 \n",
      "Epoch: 479 ... Loss: 0.47905588150024414 \n",
      "Epoch: 480 ... Loss: 0.4789023995399475 \n",
      "Epoch: 481 ... Loss: 0.47874903678894043 \n",
      "Epoch: 482 ... Loss: 0.4785957932472229 \n",
      "Epoch: 483 ... Loss: 0.47844263911247253 \n",
      "Epoch: 484 ... Loss: 0.4782896041870117 \n",
      "Epoch: 485 ... Loss: 0.4781365692615509 \n",
      "Epoch: 486 ... Loss: 0.4779837131500244 \n",
      "Epoch: 487 ... Loss: 0.47783103585243225 \n",
      "Epoch: 488 ... Loss: 0.47767841815948486 \n",
      "Epoch: 489 ... Loss: 0.47752583026885986 \n",
      "Epoch: 490 ... Loss: 0.4773733913898468 \n",
      "Epoch: 491 ... Loss: 0.4772210717201233 \n",
      "Epoch: 492 ... Loss: 0.47706878185272217 \n",
      "Epoch: 493 ... Loss: 0.47691667079925537 \n",
      "Epoch: 494 ... Loss: 0.47676461935043335 \n",
      "Epoch: 495 ... Loss: 0.4766126871109009 \n",
      "Epoch: 496 ... Loss: 0.4764608144760132 \n",
      "Epoch: 497 ... Loss: 0.4763090908527374 \n",
      "Epoch: 498 ... Loss: 0.47615742683410645 \n",
      "Epoch: 499 ... Loss: 0.4760059118270874 \n",
      "Epoch: 500 ... Loss: 0.4758545160293579 \n",
      "Epoch: 501 ... Loss: 0.4757031500339508 \n",
      "Epoch: 502 ... Loss: 0.47555187344551086 \n",
      "Epoch: 503 ... Loss: 0.47540074586868286 \n",
      "Epoch: 504 ... Loss: 0.475249707698822 \n",
      "Epoch: 505 ... Loss: 0.47509878873825073 \n",
      "Epoch: 506 ... Loss: 0.4749479591846466 \n",
      "Epoch: 507 ... Loss: 0.47479718923568726 \n",
      "Epoch: 508 ... Loss: 0.47464656829833984 \n",
      "Epoch: 509 ... Loss: 0.47449594736099243 \n",
      "Epoch: 510 ... Loss: 0.47434553503990173 \n",
      "Epoch: 511 ... Loss: 0.4741952419281006 \n",
      "Epoch: 512 ... Loss: 0.47404494881629944 \n",
      "Epoch: 513 ... Loss: 0.4738948345184326 \n",
      "Epoch: 514 ... Loss: 0.4737447202205658 \n",
      "Epoch: 515 ... Loss: 0.4735947549343109 \n",
      "Epoch: 516 ... Loss: 0.47344496846199036 \n",
      "Epoch: 517 ... Loss: 0.4732952117919922 \n",
      "Epoch: 518 ... Loss: 0.4731455445289612 \n",
      "Epoch: 519 ... Loss: 0.4729960262775421 \n",
      "Epoch: 520 ... Loss: 0.47284653782844543 \n",
      "Epoch: 521 ... Loss: 0.4726971983909607 \n",
      "Epoch: 522 ... Loss: 0.4725479483604431 \n",
      "Epoch: 523 ... Loss: 0.4723987877368927 \n",
      "Epoch: 524 ... Loss: 0.47224974632263184 \n",
      "Epoch: 525 ... Loss: 0.47210073471069336 \n",
      "Epoch: 526 ... Loss: 0.4719519019126892 \n",
      "Epoch: 527 ... Loss: 0.47180309891700745 \n",
      "Epoch: 528 ... Loss: 0.47165447473526 \n",
      "Epoch: 529 ... Loss: 0.47150588035583496 \n",
      "Epoch: 530 ... Loss: 0.47135740518569946 \n",
      "Epoch: 531 ... Loss: 0.4712090492248535 \n",
      "Epoch: 532 ... Loss: 0.47106078267097473 \n",
      "Epoch: 533 ... Loss: 0.4709126353263855 \n",
      "Epoch: 534 ... Loss: 0.47076454758644104 \n",
      "Epoch: 535 ... Loss: 0.47061648964881897 \n",
      "Epoch: 536 ... Loss: 0.4704686403274536 \n",
      "Epoch: 537 ... Loss: 0.47032085061073303 \n",
      "Epoch: 538 ... Loss: 0.4701731204986572 \n",
      "Epoch: 539 ... Loss: 0.47002556920051575 \n",
      "Epoch: 540 ... Loss: 0.46987807750701904 \n",
      "Epoch: 541 ... Loss: 0.46973058581352234 \n",
      "Epoch: 542 ... Loss: 0.46958333253860474 \n",
      "Epoch: 543 ... Loss: 0.4694361388683319 \n",
      "Epoch: 544 ... Loss: 0.46928906440734863 \n",
      "Epoch: 545 ... Loss: 0.46914198994636536 \n",
      "Epoch: 546 ... Loss: 0.46899518370628357 \n",
      "Epoch: 547 ... Loss: 0.468848317861557 \n",
      "Epoch: 548 ... Loss: 0.4687016010284424 \n",
      "Epoch: 549 ... Loss: 0.46855488419532776 \n",
      "Epoch: 550 ... Loss: 0.46840837597846985 \n",
      "Epoch: 551 ... Loss: 0.4682619869709015 \n",
      "Epoch: 552 ... Loss: 0.4681156575679779 \n",
      "Epoch: 553 ... Loss: 0.4679693579673767 \n",
      "Epoch: 554 ... Loss: 0.4678232669830322 \n",
      "Epoch: 555 ... Loss: 0.4676772356033325 \n",
      "Epoch: 556 ... Loss: 0.4675311744213104 \n",
      "Epoch: 557 ... Loss: 0.46738532185554504 \n",
      "Epoch: 558 ... Loss: 0.4672395884990692 \n",
      "Epoch: 559 ... Loss: 0.46709388494491577 \n",
      "Epoch: 560 ... Loss: 0.46694833040237427 \n",
      "Epoch: 561 ... Loss: 0.46680283546447754 \n",
      "Epoch: 562 ... Loss: 0.466657429933548 \n",
      "Epoch: 563 ... Loss: 0.46651220321655273 \n",
      "Epoch: 564 ... Loss: 0.4663669764995575 \n",
      "Epoch: 565 ... Loss: 0.4662218987941742 \n",
      "Epoch: 566 ... Loss: 0.46607691049575806 \n",
      "Epoch: 567 ... Loss: 0.4659319818019867 \n",
      "Epoch: 568 ... Loss: 0.46578720211982727 \n",
      "Epoch: 569 ... Loss: 0.46564242243766785 \n",
      "Epoch: 570 ... Loss: 0.46549779176712036 \n",
      "Epoch: 571 ... Loss: 0.4653532803058624 \n",
      "Epoch: 572 ... Loss: 0.46520882844924927 \n",
      "Epoch: 573 ... Loss: 0.46506449580192566 \n",
      "Epoch: 574 ... Loss: 0.4649202823638916 \n",
      "Epoch: 575 ... Loss: 0.46477609872817993 \n",
      "Epoch: 576 ... Loss: 0.4646320343017578 \n",
      "Epoch: 577 ... Loss: 0.46448802947998047 \n",
      "Epoch: 578 ... Loss: 0.46434420347213745 \n",
      "Epoch: 579 ... Loss: 0.4642004072666168 \n",
      "Epoch: 580 ... Loss: 0.46405673027038574 \n",
      "Epoch: 581 ... Loss: 0.4639131426811218 \n",
      "Epoch: 582 ... Loss: 0.4637696146965027 \n",
      "Epoch: 583 ... Loss: 0.46362626552581787 \n",
      "Epoch: 584 ... Loss: 0.46348291635513306 \n",
      "Epoch: 585 ... Loss: 0.46333974599838257 \n",
      "Epoch: 586 ... Loss: 0.4631965756416321 \n",
      "Epoch: 587 ... Loss: 0.4630535840988159 \n",
      "Epoch: 588 ... Loss: 0.46291065216064453 \n",
      "Epoch: 589 ... Loss: 0.4627677798271179 \n",
      "Epoch: 590 ... Loss: 0.46262508630752563 \n",
      "Epoch: 591 ... Loss: 0.46248236298561096 \n",
      "Epoch: 592 ... Loss: 0.46233975887298584 \n",
      "Epoch: 593 ... Loss: 0.46219736337661743 \n",
      "Epoch: 594 ... Loss: 0.46205490827560425 \n",
      "Epoch: 595 ... Loss: 0.4619126617908478 \n",
      "Epoch: 596 ... Loss: 0.46177050471305847 \n",
      "Epoch: 597 ... Loss: 0.46162837743759155 \n",
      "Epoch: 598 ... Loss: 0.4614863991737366 \n",
      "Epoch: 599 ... Loss: 0.46134448051452637 \n",
      "Epoch: 600 ... Loss: 0.4612026512622833 \n",
      "Epoch: 601 ... Loss: 0.46106094121932983 \n",
      "Epoch: 602 ... Loss: 0.46091923117637634 \n",
      "Epoch: 603 ... Loss: 0.4607776999473572 \n",
      "Epoch: 604 ... Loss: 0.4606362283229828 \n",
      "Epoch: 605 ... Loss: 0.4604949355125427 \n",
      "Epoch: 606 ... Loss: 0.4603536128997803 \n",
      "Epoch: 607 ... Loss: 0.4602124094963074 \n",
      "Epoch: 608 ... Loss: 0.4600713551044464 \n",
      "Epoch: 609 ... Loss: 0.4599303603172302 \n",
      "Epoch: 610 ... Loss: 0.459789514541626 \n",
      "Epoch: 611 ... Loss: 0.45964866876602173 \n",
      "Epoch: 612 ... Loss: 0.45950794219970703 \n",
      "Epoch: 613 ... Loss: 0.4593673050403595 \n",
      "Epoch: 614 ... Loss: 0.4592267870903015 \n",
      "Epoch: 615 ... Loss: 0.4590863585472107 \n",
      "Epoch: 616 ... Loss: 0.45894595980644226 \n",
      "Epoch: 617 ... Loss: 0.45880571007728577 \n",
      "Epoch: 618 ... Loss: 0.4586655795574188 \n",
      "Epoch: 619 ... Loss: 0.4585254192352295 \n",
      "Epoch: 620 ... Loss: 0.4583854377269745 \n",
      "Epoch: 621 ... Loss: 0.45824557542800903 \n",
      "Epoch: 622 ... Loss: 0.45810577273368835 \n",
      "Epoch: 623 ... Loss: 0.4579659700393677 \n",
      "Epoch: 624 ... Loss: 0.4578264057636261 \n",
      "Epoch: 625 ... Loss: 0.4576868712902069 \n",
      "Epoch: 626 ... Loss: 0.4575473964214325 \n",
      "Epoch: 627 ... Loss: 0.4574081003665924 \n",
      "Epoch: 628 ... Loss: 0.45726877450942993 \n",
      "Epoch: 629 ... Loss: 0.4571295976638794 \n",
      "Epoch: 630 ... Loss: 0.45699048042297363 \n",
      "Epoch: 631 ... Loss: 0.4568515121936798 \n",
      "Epoch: 632 ... Loss: 0.4567125737667084 \n",
      "Epoch: 633 ... Loss: 0.4565737843513489 \n",
      "Epoch: 634 ... Loss: 0.45643508434295654 \n",
      "Epoch: 635 ... Loss: 0.45629647374153137 \n",
      "Epoch: 636 ... Loss: 0.4561578333377838 \n",
      "Epoch: 637 ... Loss: 0.45601946115493774 \n",
      "Epoch: 638 ... Loss: 0.4558810889720917 \n",
      "Epoch: 639 ... Loss: 0.45574280619621277 \n",
      "Epoch: 640 ... Loss: 0.455604612827301 \n",
      "Epoch: 641 ... Loss: 0.45546650886535645 \n",
      "Epoch: 642 ... Loss: 0.4553285241127014 \n",
      "Epoch: 643 ... Loss: 0.45519059896469116 \n",
      "Epoch: 644 ... Loss: 0.4550527334213257 \n",
      "Epoch: 645 ... Loss: 0.45491498708724976 \n",
      "Epoch: 646 ... Loss: 0.4547773599624634 \n",
      "Epoch: 647 ... Loss: 0.4546397924423218 \n",
      "Epoch: 648 ... Loss: 0.45450231432914734 \n",
      "Epoch: 649 ... Loss: 0.4543648660182953 \n",
      "Epoch: 650 ... Loss: 0.4542275667190552 \n",
      "Epoch: 651 ... Loss: 0.4540903866291046 \n",
      "Epoch: 652 ... Loss: 0.45395323634147644 \n",
      "Epoch: 653 ... Loss: 0.4538162648677826 \n",
      "Epoch: 654 ... Loss: 0.45367926359176636 \n",
      "Epoch: 655 ... Loss: 0.45354244112968445 \n",
      "Epoch: 656 ... Loss: 0.4534056782722473 \n",
      "Epoch: 657 ... Loss: 0.45326894521713257 \n",
      "Epoch: 658 ... Loss: 0.4531323313713074 \n",
      "Epoch: 659 ... Loss: 0.4529959559440613 \n",
      "Epoch: 660 ... Loss: 0.45285946130752563 \n",
      "Epoch: 661 ... Loss: 0.4527231454849243 \n",
      "Epoch: 662 ... Loss: 0.45258691906929016 \n",
      "Epoch: 663 ... Loss: 0.4524507224559784 \n",
      "Epoch: 664 ... Loss: 0.45231467485427856 \n",
      "Epoch: 665 ... Loss: 0.4521787166595459 \n",
      "Epoch: 666 ... Loss: 0.452042818069458 \n",
      "Epoch: 667 ... Loss: 0.4519069790840149 \n",
      "Epoch: 668 ... Loss: 0.4517713785171509 \n",
      "Epoch: 669 ... Loss: 0.4516356885433197 \n",
      "Epoch: 670 ... Loss: 0.45150014758110046 \n",
      "Epoch: 671 ... Loss: 0.4513646960258484 \n",
      "Epoch: 672 ... Loss: 0.4512293040752411 \n",
      "Epoch: 673 ... Loss: 0.4510940909385681 \n",
      "Epoch: 674 ... Loss: 0.45095890760421753 \n",
      "Epoch: 675 ... Loss: 0.45082372426986694 \n",
      "Epoch: 676 ... Loss: 0.4506887197494507 \n",
      "Epoch: 677 ... Loss: 0.4505537748336792 \n",
      "Epoch: 678 ... Loss: 0.4504189193248749 \n",
      "Epoch: 679 ... Loss: 0.45028412342071533 \n",
      "Epoch: 680 ... Loss: 0.4501494765281677 \n",
      "Epoch: 681 ... Loss: 0.4500149190425873 \n",
      "Epoch: 682 ... Loss: 0.4498803913593292 \n",
      "Epoch: 683 ... Loss: 0.44974595308303833 \n",
      "Epoch: 684 ... Loss: 0.4496116042137146 \n",
      "Epoch: 685 ... Loss: 0.4494773745536804 \n",
      "Epoch: 686 ... Loss: 0.4493432343006134 \n",
      "Epoch: 687 ... Loss: 0.4492091238498688 \n",
      "Epoch: 688 ... Loss: 0.4490751326084137 \n",
      "Epoch: 689 ... Loss: 0.4489412307739258 \n",
      "Epoch: 690 ... Loss: 0.44880738854408264 \n",
      "Epoch: 691 ... Loss: 0.44867366552352905 \n",
      "Epoch: 692 ... Loss: 0.4485400319099426 \n",
      "Epoch: 693 ... Loss: 0.44840651750564575 \n",
      "Epoch: 694 ... Loss: 0.44827306270599365 \n",
      "Epoch: 695 ... Loss: 0.44813963770866394 \n",
      "Epoch: 696 ... Loss: 0.44800636172294617 \n",
      "Epoch: 697 ... Loss: 0.447873055934906 \n",
      "Epoch: 698 ... Loss: 0.44774001836776733 \n",
      "Epoch: 699 ... Loss: 0.4476069509983063 \n",
      "Epoch: 700 ... Loss: 0.44747394323349 \n",
      "Epoch: 701 ... Loss: 0.44734108448028564 \n",
      "Epoch: 702 ... Loss: 0.44720831513404846 \n",
      "Epoch: 703 ... Loss: 0.4470755457878113 \n",
      "Epoch: 704 ... Loss: 0.4469429850578308 \n",
      "Epoch: 705 ... Loss: 0.44681042432785034 \n",
      "Epoch: 706 ... Loss: 0.4466779828071594 \n",
      "Epoch: 707 ... Loss: 0.44654563069343567 \n",
      "Epoch: 708 ... Loss: 0.4464133083820343 \n",
      "Epoch: 709 ... Loss: 0.44628116488456726 \n",
      "Epoch: 710 ... Loss: 0.44614899158477783 \n",
      "Epoch: 711 ... Loss: 0.4460170269012451 \n",
      "Epoch: 712 ... Loss: 0.44588503241539 \n",
      "Epoch: 713 ... Loss: 0.44575318694114685 \n",
      "Epoch: 714 ... Loss: 0.44562143087387085 \n",
      "Epoch: 715 ... Loss: 0.4454897344112396 \n",
      "Epoch: 716 ... Loss: 0.4453580379486084 \n",
      "Epoch: 717 ... Loss: 0.4452265501022339 \n",
      "Epoch: 718 ... Loss: 0.44509509205818176 \n",
      "Epoch: 719 ... Loss: 0.4449637830257416 \n",
      "Epoch: 720 ... Loss: 0.4448324739933014 \n",
      "Epoch: 721 ... Loss: 0.44470128417015076 \n",
      "Epoch: 722 ... Loss: 0.4445701539516449 \n",
      "Epoch: 723 ... Loss: 0.44443920254707336 \n",
      "Epoch: 724 ... Loss: 0.44430819153785706 \n",
      "Epoch: 725 ... Loss: 0.44417738914489746 \n",
      "Epoch: 726 ... Loss: 0.44404658675193787 \n",
      "Epoch: 727 ... Loss: 0.4439159333705902 \n",
      "Epoch: 728 ... Loss: 0.44378527998924255 \n",
      "Epoch: 729 ... Loss: 0.44365477561950684 \n",
      "Epoch: 730 ... Loss: 0.4435243010520935 \n",
      "Epoch: 731 ... Loss: 0.4433939456939697 \n",
      "Epoch: 732 ... Loss: 0.4432636499404907 \n",
      "Epoch: 733 ... Loss: 0.44313350319862366 \n",
      "Epoch: 734 ... Loss: 0.4430033564567566 \n",
      "Epoch: 735 ... Loss: 0.4428732991218567 \n",
      "Epoch: 736 ... Loss: 0.4427433907985687 \n",
      "Epoch: 737 ... Loss: 0.44261351227760315 \n",
      "Epoch: 738 ... Loss: 0.4424837827682495 \n",
      "Epoch: 739 ... Loss: 0.4423540532588959 \n",
      "Epoch: 740 ... Loss: 0.4422244429588318 \n",
      "Epoch: 741 ... Loss: 0.4420948922634125 \n",
      "Epoch: 742 ... Loss: 0.4419654607772827 \n",
      "Epoch: 743 ... Loss: 0.44183605909347534 \n",
      "Epoch: 744 ... Loss: 0.4417067766189575 \n",
      "Epoch: 745 ... Loss: 0.4415775537490845 \n",
      "Epoch: 746 ... Loss: 0.44144847989082336 \n",
      "Epoch: 747 ... Loss: 0.44131940603256226 \n",
      "Epoch: 748 ... Loss: 0.4411904215812683 \n",
      "Epoch: 749 ... Loss: 0.4410615563392639 \n",
      "Epoch: 750 ... Loss: 0.4409328103065491 \n",
      "Epoch: 751 ... Loss: 0.44080406427383423 \n",
      "Epoch: 752 ... Loss: 0.44067543745040894 \n",
      "Epoch: 753 ... Loss: 0.4405469298362732 \n",
      "Epoch: 754 ... Loss: 0.4404183626174927 \n",
      "Epoch: 755 ... Loss: 0.44029003381729126 \n",
      "Epoch: 756 ... Loss: 0.44016173481941223 \n",
      "Epoch: 757 ... Loss: 0.4400334656238556 \n",
      "Epoch: 758 ... Loss: 0.4399053454399109 \n",
      "Epoch: 759 ... Loss: 0.43977728486061096 \n",
      "Epoch: 760 ... Loss: 0.43964922428131104 \n",
      "Epoch: 761 ... Loss: 0.4395213723182678 \n",
      "Epoch: 762 ... Loss: 0.4393935203552246 \n",
      "Epoch: 763 ... Loss: 0.4392658770084381 \n",
      "Epoch: 764 ... Loss: 0.43913814425468445 \n",
      "Epoch: 765 ... Loss: 0.4390105605125427 \n",
      "Epoch: 766 ... Loss: 0.4388830065727234 \n",
      "Epoch: 767 ... Loss: 0.43875566124916077 \n",
      "Epoch: 768 ... Loss: 0.43862828612327576 \n",
      "Epoch: 769 ... Loss: 0.4385010302066803 \n",
      "Epoch: 770 ... Loss: 0.438373863697052 \n",
      "Epoch: 771 ... Loss: 0.4382467567920685 \n",
      "Epoch: 772 ... Loss: 0.4381197392940521 \n",
      "Epoch: 773 ... Loss: 0.43799281120300293 \n",
      "Epoch: 774 ... Loss: 0.4378659129142761 \n",
      "Epoch: 775 ... Loss: 0.43773916363716125 \n",
      "Epoch: 776 ... Loss: 0.43761253356933594 \n",
      "Epoch: 777 ... Loss: 0.43748581409454346 \n",
      "Epoch: 778 ... Loss: 0.4373592734336853 \n",
      "Epoch: 779 ... Loss: 0.4372328221797943 \n",
      "Epoch: 780 ... Loss: 0.43710649013519287 \n",
      "Epoch: 781 ... Loss: 0.4369801878929138 \n",
      "Epoch: 782 ... Loss: 0.43685394525527954 \n",
      "Epoch: 783 ... Loss: 0.4367278218269348 \n",
      "Epoch: 784 ... Loss: 0.43660175800323486 \n",
      "Epoch: 785 ... Loss: 0.4364757537841797 \n",
      "Epoch: 786 ... Loss: 0.43634986877441406 \n",
      "Epoch: 787 ... Loss: 0.4362240433692932 \n",
      "Epoch: 788 ... Loss: 0.43609827756881714 \n",
      "Epoch: 789 ... Loss: 0.435972660779953 \n",
      "Epoch: 790 ... Loss: 0.4358470141887665 \n",
      "Epoch: 791 ... Loss: 0.4357214868068695 \n",
      "Epoch: 792 ... Loss: 0.4355961084365845 \n",
      "Epoch: 793 ... Loss: 0.4354707598686218 \n",
      "Epoch: 794 ... Loss: 0.43534547090530396 \n",
      "Epoch: 795 ... Loss: 0.43522030115127563 \n",
      "Epoch: 796 ... Loss: 0.4350951910018921 \n",
      "Epoch: 797 ... Loss: 0.43497011065483093 \n",
      "Epoch: 798 ... Loss: 0.4348451495170593 \n",
      "Epoch: 799 ... Loss: 0.4347202777862549 \n",
      "Epoch: 800 ... Loss: 0.4345954656600952 \n",
      "Epoch: 801 ... Loss: 0.4344707727432251 \n",
      "Epoch: 802 ... Loss: 0.43434616923332214 \n",
      "Epoch: 803 ... Loss: 0.4342215657234192 \n",
      "Epoch: 804 ... Loss: 0.4340970814228058 \n",
      "Epoch: 805 ... Loss: 0.43397268652915955 \n",
      "Epoch: 806 ... Loss: 0.4338482618331909 \n",
      "Epoch: 807 ... Loss: 0.4337241053581238 \n",
      "Epoch: 808 ... Loss: 0.43359988927841187 \n",
      "Epoch: 809 ... Loss: 0.4334757924079895 \n",
      "Epoch: 810 ... Loss: 0.4333518147468567 \n",
      "Epoch: 811 ... Loss: 0.4332278370857239 \n",
      "Epoch: 812 ... Loss: 0.4331040680408478 \n",
      "Epoch: 813 ... Loss: 0.4329802393913269 \n",
      "Epoch: 814 ... Loss: 0.4328565299510956 \n",
      "Epoch: 815 ... Loss: 0.43273288011550903 \n",
      "Epoch: 816 ... Loss: 0.43260928988456726 \n",
      "Epoch: 817 ... Loss: 0.43248578906059265 \n",
      "Epoch: 818 ... Loss: 0.4323624074459076 \n",
      "Epoch: 819 ... Loss: 0.4322390854358673 \n",
      "Epoch: 820 ... Loss: 0.4321158528327942 \n",
      "Epoch: 821 ... Loss: 0.43199267983436584 \n",
      "Epoch: 822 ... Loss: 0.43186959624290466 \n",
      "Epoch: 823 ... Loss: 0.43174654245376587 \n",
      "Epoch: 824 ... Loss: 0.4316236078739166 \n",
      "Epoch: 825 ... Loss: 0.43150076270103455 \n",
      "Epoch: 826 ... Loss: 0.43137797713279724 \n",
      "Epoch: 827 ... Loss: 0.4312553107738495 \n",
      "Epoch: 828 ... Loss: 0.43113264441490173 \n",
      "Epoch: 829 ... Loss: 0.4310101270675659 \n",
      "Epoch: 830 ... Loss: 0.4308876395225525 \n",
      "Epoch: 831 ... Loss: 0.43076521158218384 \n",
      "Epoch: 832 ... Loss: 0.43064284324645996 \n",
      "Epoch: 833 ... Loss: 0.4305206835269928 \n",
      "Epoch: 834 ... Loss: 0.43039846420288086 \n",
      "Epoch: 835 ... Loss: 0.4302763342857361 \n",
      "Epoch: 836 ... Loss: 0.43015438318252563 \n",
      "Epoch: 837 ... Loss: 0.4300324320793152 \n",
      "Epoch: 838 ... Loss: 0.4299105107784271 \n",
      "Epoch: 839 ... Loss: 0.4297886788845062 \n",
      "Epoch: 840 ... Loss: 0.42966705560684204 \n",
      "Epoch: 841 ... Loss: 0.4295453727245331 \n",
      "Epoch: 842 ... Loss: 0.42942380905151367 \n",
      "Epoch: 843 ... Loss: 0.4293023347854614 \n",
      "Epoch: 844 ... Loss: 0.42918089032173157 \n",
      "Epoch: 845 ... Loss: 0.42905956506729126 \n",
      "Epoch: 846 ... Loss: 0.42893826961517334 \n",
      "Epoch: 847 ... Loss: 0.42881715297698975 \n",
      "Epoch: 848 ... Loss: 0.428695946931839 \n",
      "Epoch: 849 ... Loss: 0.42857494950294495 \n",
      "Epoch: 850 ... Loss: 0.4284539818763733 \n",
      "Epoch: 851 ... Loss: 0.4283330738544464 \n",
      "Epoch: 852 ... Loss: 0.4282122850418091 \n",
      "Epoch: 853 ... Loss: 0.42809155583381653 \n",
      "Epoch: 854 ... Loss: 0.4279709458351135 \n",
      "Epoch: 855 ... Loss: 0.42785030603408813 \n",
      "Epoch: 856 ... Loss: 0.4277297854423523 \n",
      "Epoch: 857 ... Loss: 0.4276093542575836 \n",
      "Epoch: 858 ... Loss: 0.42748895287513733 \n",
      "Epoch: 859 ... Loss: 0.4273686408996582 \n",
      "Epoch: 860 ... Loss: 0.427248477935791 \n",
      "Epoch: 861 ... Loss: 0.4271283447742462 \n",
      "Epoch: 862 ... Loss: 0.4270082712173462 \n",
      "Epoch: 863 ... Loss: 0.42688828706741333 \n",
      "Epoch: 864 ... Loss: 0.42676836252212524 \n",
      "Epoch: 865 ... Loss: 0.4266485571861267 \n",
      "Epoch: 866 ... Loss: 0.42652878165245056 \n",
      "Epoch: 867 ... Loss: 0.4264090657234192 \n",
      "Epoch: 868 ... Loss: 0.42628946900367737 \n",
      "Epoch: 869 ... Loss: 0.42616987228393555 \n",
      "Epoch: 870 ... Loss: 0.42605045437812805 \n",
      "Epoch: 871 ... Loss: 0.42593109607696533 \n",
      "Epoch: 872 ... Loss: 0.4258117079734802 \n",
      "Epoch: 873 ... Loss: 0.42569246888160706 \n",
      "Epoch: 874 ... Loss: 0.4255732297897339 \n",
      "Epoch: 875 ... Loss: 0.42545416951179504 \n",
      "Epoch: 876 ... Loss: 0.425335168838501 \n",
      "Epoch: 877 ... Loss: 0.4252161979675293 \n",
      "Epoch: 878 ... Loss: 0.4250973165035248 \n",
      "Epoch: 879 ... Loss: 0.42497849464416504 \n",
      "Epoch: 880 ... Loss: 0.4248597323894501 \n",
      "Epoch: 881 ... Loss: 0.42474114894866943 \n",
      "Epoch: 882 ... Loss: 0.4246225655078888 \n",
      "Epoch: 883 ... Loss: 0.42450398206710815 \n",
      "Epoch: 884 ... Loss: 0.42438557744026184 \n",
      "Epoch: 885 ... Loss: 0.4242672026157379 \n",
      "Epoch: 886 ... Loss: 0.42414888739585876 \n",
      "Epoch: 887 ... Loss: 0.424030601978302 \n",
      "Epoch: 888 ... Loss: 0.42391249537467957 \n",
      "Epoch: 889 ... Loss: 0.4237944483757019 \n",
      "Epoch: 890 ... Loss: 0.423676460981369 \n",
      "Epoch: 891 ... Loss: 0.42355847358703613 \n",
      "Epoch: 892 ... Loss: 0.4234405755996704 \n",
      "Epoch: 893 ... Loss: 0.423322856426239 \n",
      "Epoch: 894 ... Loss: 0.42320510745048523 \n",
      "Epoch: 895 ... Loss: 0.4230874478816986 \n",
      "Epoch: 896 ... Loss: 0.42296990752220154 \n",
      "Epoch: 897 ... Loss: 0.42285242676734924 \n",
      "Epoch: 898 ... Loss: 0.4227350056171417 \n",
      "Epoch: 899 ... Loss: 0.4226176142692566 \n",
      "Epoch: 900 ... Loss: 0.4225003719329834 \n",
      "Epoch: 901 ... Loss: 0.4223830997943878 \n",
      "Epoch: 902 ... Loss: 0.4222659766674042 \n",
      "Epoch: 903 ... Loss: 0.4221489429473877 \n",
      "Epoch: 904 ... Loss: 0.4220319390296936 \n",
      "Epoch: 905 ... Loss: 0.42191505432128906 \n",
      "Epoch: 906 ... Loss: 0.4217981994152069 \n",
      "Epoch: 907 ... Loss: 0.4216814339160919 \n",
      "Epoch: 908 ... Loss: 0.4215646982192993 \n",
      "Epoch: 909 ... Loss: 0.4214480519294739 \n",
      "Epoch: 910 ... Loss: 0.421331524848938 \n",
      "Epoch: 911 ... Loss: 0.4212150573730469 \n",
      "Epoch: 912 ... Loss: 0.42109861969947815 \n",
      "Epoch: 913 ... Loss: 0.4209822714328766 \n",
      "Epoch: 914 ... Loss: 0.4208659529685974 \n",
      "Epoch: 915 ... Loss: 0.4207497537136078 \n",
      "Epoch: 916 ... Loss: 0.4206337034702301 \n",
      "Epoch: 917 ... Loss: 0.42051756381988525 \n",
      "Epoch: 918 ... Loss: 0.4204016327857971 \n",
      "Epoch: 919 ... Loss: 0.4202856421470642 \n",
      "Epoch: 920 ... Loss: 0.420169860124588 \n",
      "Epoch: 921 ... Loss: 0.42005401849746704 \n",
      "Epoch: 922 ... Loss: 0.419938325881958 \n",
      "Epoch: 923 ... Loss: 0.41982269287109375 \n",
      "Epoch: 924 ... Loss: 0.41970714926719666 \n",
      "Epoch: 925 ... Loss: 0.41959163546562195 \n",
      "Epoch: 926 ... Loss: 0.4194762706756592 \n",
      "Epoch: 927 ... Loss: 0.419360876083374 \n",
      "Epoch: 928 ... Loss: 0.4192456007003784 \n",
      "Epoch: 929 ... Loss: 0.41913041472435 \n",
      "Epoch: 930 ... Loss: 0.4190152883529663 \n",
      "Epoch: 931 ... Loss: 0.41890019178390503 \n",
      "Epoch: 932 ... Loss: 0.4187851846218109 \n",
      "Epoch: 933 ... Loss: 0.4186702370643616 \n",
      "Epoch: 934 ... Loss: 0.4185553789138794 \n",
      "Epoch: 935 ... Loss: 0.418440580368042 \n",
      "Epoch: 936 ... Loss: 0.41832593083381653 \n",
      "Epoch: 937 ... Loss: 0.4182112216949463 \n",
      "Epoch: 938 ... Loss: 0.4180966317653656 \n",
      "Epoch: 939 ... Loss: 0.4179821014404297 \n",
      "Epoch: 940 ... Loss: 0.4178677201271057 \n",
      "Epoch: 941 ... Loss: 0.41775333881378174 \n",
      "Epoch: 942 ... Loss: 0.4176390767097473 \n",
      "Epoch: 943 ... Loss: 0.4175247848033905 \n",
      "Epoch: 944 ... Loss: 0.417410671710968 \n",
      "Epoch: 945 ... Loss: 0.41729652881622314 \n",
      "Epoch: 946 ... Loss: 0.4171825349330902 \n",
      "Epoch: 947 ... Loss: 0.41706860065460205 \n",
      "Epoch: 948 ... Loss: 0.4169546961784363 \n",
      "Epoch: 949 ... Loss: 0.41684091091156006 \n",
      "Epoch: 950 ... Loss: 0.41672712564468384 \n",
      "Epoch: 951 ... Loss: 0.41661345958709717 \n",
      "Epoch: 952 ... Loss: 0.4164998531341553 \n",
      "Epoch: 953 ... Loss: 0.41638627648353577 \n",
      "Epoch: 954 ... Loss: 0.4162728190422058 \n",
      "Epoch: 955 ... Loss: 0.416159451007843 \n",
      "Epoch: 956 ... Loss: 0.416046142578125 \n",
      "Epoch: 957 ... Loss: 0.41593286395072937 \n",
      "Epoch: 958 ... Loss: 0.4158197045326233 \n",
      "Epoch: 959 ... Loss: 0.4157065451145172 \n",
      "Epoch: 960 ... Loss: 0.4155935049057007 \n",
      "Epoch: 961 ... Loss: 0.41548052430152893 \n",
      "Epoch: 962 ... Loss: 0.41536760330200195 \n",
      "Epoch: 963 ... Loss: 0.41525477170944214 \n",
      "Epoch: 964 ... Loss: 0.4151419699192047 \n",
      "Epoch: 965 ... Loss: 0.41502925753593445 \n",
      "Epoch: 966 ... Loss: 0.41491663455963135 \n",
      "Epoch: 967 ... Loss: 0.41480404138565063 \n",
      "Epoch: 968 ... Loss: 0.4146915674209595 \n",
      "Epoch: 969 ... Loss: 0.4145791232585907 \n",
      "Epoch: 970 ... Loss: 0.4144667387008667 \n",
      "Epoch: 971 ... Loss: 0.41435450315475464 \n",
      "Epoch: 972 ... Loss: 0.4142421782016754 \n",
      "Epoch: 973 ... Loss: 0.4141300618648529 \n",
      "Epoch: 974 ... Loss: 0.4140179455280304 \n",
      "Epoch: 975 ... Loss: 0.41390591859817505 \n",
      "Epoch: 976 ... Loss: 0.41379398107528687 \n",
      "Epoch: 977 ... Loss: 0.41368210315704346 \n",
      "Epoch: 978 ... Loss: 0.41357022523880005 \n",
      "Epoch: 979 ... Loss: 0.4134584963321686 \n",
      "Epoch: 980 ... Loss: 0.4133467972278595 \n",
      "Epoch: 981 ... Loss: 0.41323521733283997 \n",
      "Epoch: 982 ... Loss: 0.41312360763549805 \n",
      "Epoch: 983 ... Loss: 0.41301217675209045 \n",
      "Epoch: 984 ... Loss: 0.4129007160663605 \n",
      "Epoch: 985 ... Loss: 0.41278940439224243 \n",
      "Epoch: 986 ... Loss: 0.4126780927181244 \n",
      "Epoch: 987 ... Loss: 0.4125668704509735 \n",
      "Epoch: 988 ... Loss: 0.4124557375907898 \n",
      "Epoch: 989 ... Loss: 0.41234463453292847 \n",
      "Epoch: 990 ... Loss: 0.4122336506843567 \n",
      "Epoch: 991 ... Loss: 0.4121226966381073 \n",
      "Epoch: 992 ... Loss: 0.4120118021965027 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 993 ... Loss: 0.41190096735954285 \n",
      "Epoch: 994 ... Loss: 0.4117901921272278 \n",
      "Epoch: 995 ... Loss: 0.4116795063018799 \n",
      "Epoch: 996 ... Loss: 0.41156893968582153 \n",
      "Epoch: 997 ... Loss: 0.4114583432674408 \n",
      "Epoch: 998 ... Loss: 0.411347895860672 \n",
      "Epoch: 999 ... Loss: 0.41123753786087036 \n",
      "Epoch: 1000 ... Loss: 0.41112715005874634 \n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "for epoch in range(1000):\n",
    "    y_pred = model.forward(x_data)\n",
    "    \n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch+1} ... Loss: {loss.item()} ')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (after training) 7    0.982448160648346\n"
     ]
    }
   ],
   "source": [
    "our_var = tensor([[7.0]])\n",
    "y_pred = model.forward(our_var)\n",
    "\n",
    "print(\"Prediction (after training)\",  7, '  ', model(our_var).data[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17_p38",
   "language": "python",
   "name": "pytorch17_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d6db7c5030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2345) #literally seed, just put to make random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', '0'] #for casting char 2 idx 012340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [0,1,0,2,3,3] # 'hihell' for input\n",
    "one_hot_lookup = [[1,0,0,0,0], #0\n",
    "                  [0,1,0,0,0], #1\n",
    "                  [0,0,1,0,0], #2\n",
    "                  [0,0,0,1,0], #3\n",
    "                  [0,0,0,0,1]] #4\n",
    "\n",
    "y_data = [1,0,2,3,3,4] #target output\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = Variable(torch.Tensor(x_one_hot))\n",
    "labels = Variable(torch.LongTensor(y_data))\n",
    "\n",
    "num_classes = 5\n",
    "input_size = 5\n",
    "hidden_size = 5\n",
    "batch_size = 1\n",
    "sequence_length = 6\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        \n",
    "    def forward(self, hidden, x):\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        return hidden, out.view(-1, num_classes)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))\n",
    "    \n",
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ihell0, epoch: 1, loss: 2.650\n",
      "ihell0, epoch: 2, loss: 2.650\n",
      "ihell0, epoch: 3, loss: 2.650\n",
      "ihell0, epoch: 4, loss: 2.650\n",
      "ihell0, epoch: 5, loss: 2.651\n",
      "ihell0, epoch: 6, loss: 2.650\n",
      "ihell0, epoch: 7, loss: 2.650\n",
      "ihell0, epoch: 8, loss: 2.650\n",
      "ihell0, epoch: 9, loss: 2.650\n",
      "ihell0, epoch: 10, loss: 2.650\n",
      "ihell0, epoch: 11, loss: 2.650\n",
      "ihell0, epoch: 12, loss: 2.650\n",
      "ihell0, epoch: 13, loss: 2.650\n",
      "ihell0, epoch: 14, loss: 2.649\n",
      "ihell0, epoch: 15, loss: 2.649\n",
      "ihell0, epoch: 16, loss: 2.649\n",
      "ihell0, epoch: 17, loss: 2.649\n",
      "ihell0, epoch: 18, loss: 2.649\n",
      "ihell0, epoch: 19, loss: 2.649\n",
      "ihell0, epoch: 20, loss: 2.649\n",
      "ihell0, epoch: 21, loss: 2.649\n",
      "ihell0, epoch: 22, loss: 2.649\n",
      "ihell0, epoch: 23, loss: 2.649\n",
      "ihell0, epoch: 24, loss: 2.649\n",
      "ihell0, epoch: 25, loss: 2.649\n",
      "ihell0, epoch: 26, loss: 2.649\n",
      "ihell0, epoch: 27, loss: 2.649\n",
      "ihell0, epoch: 28, loss: 2.649\n",
      "ihell0, epoch: 29, loss: 2.649\n",
      "ihell0, epoch: 30, loss: 2.649\n",
      "ihell0, epoch: 31, loss: 2.649\n",
      "ihell0, epoch: 32, loss: 2.649\n",
      "ihell0, epoch: 33, loss: 2.649\n",
      "ihell0, epoch: 34, loss: 2.649\n",
      "ihell0, epoch: 35, loss: 2.650\n",
      "ihell0, epoch: 36, loss: 2.649\n",
      "ihell0, epoch: 37, loss: 2.649\n",
      "ihell0, epoch: 38, loss: 2.649\n",
      "ihell0, epoch: 39, loss: 2.649\n",
      "ihell0, epoch: 40, loss: 2.649\n",
      "ihell0, epoch: 41, loss: 2.649\n",
      "ihell0, epoch: 42, loss: 2.648\n",
      "ihell0, epoch: 43, loss: 2.648\n",
      "ihell0, epoch: 44, loss: 2.648\n",
      "ihell0, epoch: 45, loss: 2.648\n",
      "ihell0, epoch: 46, loss: 2.648\n",
      "ihell0, epoch: 47, loss: 2.648\n",
      "ihell0, epoch: 48, loss: 2.648\n",
      "ihell0, epoch: 49, loss: 2.648\n",
      "ihell0, epoch: 50, loss: 2.648\n",
      "ihell0, epoch: 51, loss: 2.648\n",
      "ihell0, epoch: 52, loss: 2.648\n",
      "ihell0, epoch: 53, loss: 2.648\n",
      "ihell0, epoch: 54, loss: 2.648\n",
      "ihell0, epoch: 55, loss: 2.648\n",
      "ihell0, epoch: 56, loss: 2.648\n",
      "ihell0, epoch: 57, loss: 2.648\n",
      "ihell0, epoch: 58, loss: 2.648\n",
      "ihell0, epoch: 59, loss: 2.648\n",
      "ihell0, epoch: 60, loss: 2.648\n",
      "ihell0, epoch: 61, loss: 2.649\n",
      "ihell0, epoch: 62, loss: 2.648\n",
      "ihell0, epoch: 63, loss: 2.648\n",
      "ihell0, epoch: 64, loss: 2.648\n",
      "ihell0, epoch: 65, loss: 2.648\n",
      "ihell0, epoch: 66, loss: 2.648\n",
      "ihell0, epoch: 67, loss: 2.648\n",
      "ihell0, epoch: 68, loss: 2.648\n",
      "ihell0, epoch: 69, loss: 2.648\n",
      "ihell0, epoch: 70, loss: 2.648\n",
      "ihell0, epoch: 71, loss: 2.647\n",
      "ihell0, epoch: 72, loss: 2.647\n",
      "ihell0, epoch: 73, loss: 2.647\n",
      "ihell0, epoch: 74, loss: 2.647\n",
      "ihell0, epoch: 75, loss: 2.647\n",
      "ihell0, epoch: 76, loss: 2.647\n",
      "ihell0, epoch: 77, loss: 2.647\n",
      "ihell0, epoch: 78, loss: 2.647\n",
      "ihell0, epoch: 79, loss: 2.647\n",
      "ihell0, epoch: 80, loss: 2.647\n",
      "ihell0, epoch: 81, loss: 2.647\n",
      "ihell0, epoch: 82, loss: 2.647\n",
      "ihell0, epoch: 83, loss: 2.647\n",
      "ihell0, epoch: 84, loss: 2.647\n",
      "ihell0, epoch: 85, loss: 2.648\n",
      "ihell0, epoch: 86, loss: 2.647\n",
      "ihell0, epoch: 87, loss: 2.648\n",
      "ihell0, epoch: 88, loss: 2.647\n",
      "ihell0, epoch: 89, loss: 2.647\n",
      "ihell0, epoch: 90, loss: 2.647\n",
      "ihell0, epoch: 91, loss: 2.647\n",
      "ihell0, epoch: 92, loss: 2.647\n",
      "ihell0, epoch: 93, loss: 2.647\n",
      "ihell0, epoch: 94, loss: 2.647\n",
      "ihell0, epoch: 95, loss: 2.647\n",
      "ihell0, epoch: 96, loss: 2.647\n",
      "ihell0, epoch: 97, loss: 2.647\n",
      "ihell0, epoch: 98, loss: 2.647\n",
      "ihell0, epoch: 99, loss: 2.647\n",
      "ihell0, epoch: 100, loss: 2.647\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    #optim, loss, hidden initializing\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden, output = model(hidden, input)\n",
    "        val, idx = output.max(1)\n",
    "        sys.stdout.write(idx2char[idx.data[0]])\n",
    "        loss += criterion(output, torch.LongTensor([label]))\n",
    "\n",
    "    print(\", epoch: %d, loss: %1.3f\" % (epoch + 1, loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17_p38",
   "language": "python",
   "name": "pytorch17_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

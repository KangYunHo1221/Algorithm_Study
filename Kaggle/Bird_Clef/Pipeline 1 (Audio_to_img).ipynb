{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "'''\n",
    "                 PIPE LINE 1\n",
    "                 Data 전처리\n",
    "              melspec computing\n",
    "                                              '''\n",
    "###############################################\n",
    "\n",
    "\n",
    "''' \n",
    "    \n",
    "    \n",
    "    \n",
    "데이터 셋이 너무 큰 경우 Part_id 로 쪼개서 작업할수도 있음\n",
    "get_df 에서 학습용 df 전처리 하는게 유리할것. (df.rating이 일정이하면 학습에 안쓰겠다 등등)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from  soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from  IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from  ast import literal_eval\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Seed Setting ##\n",
    "##################\n",
    "\n",
    "def make_seed(seed = 499):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "make_seed()\n",
    "\n",
    "Num_classes = 397 ##label할 classes 갯수(ex 새 종류)\n",
    "SR = 32000 #sampling rate\n",
    "Duration = 7 #time\n",
    "seed = 599\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio_images', 'Label_IDS.json', 'resnet152_sr32000_d7_v1_v1', 'resnext_sr32000_d7_v1_v1', 'rich_train_metadata.csv', 'sample_submission.csv', 'test.csv', 'test_soundscapes', 'train_metadata.csv', 'train_short_audio', 'train_soundscapes', 'train_soundscape_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "## Path manage ##\n",
    "#################\n",
    "\n",
    "Root_Path = '/Users/ansgh/PycharmProjects/kaggle_notebook/input/birdclef-2021'\n",
    "\n",
    "Train_short_root = Path(Root_Path + str('/train_short_audio'))\n",
    "Train_metadata_root = Path(Root_Path + str('/train_metadata.csv'))\n",
    "\n",
    "Train_audio_image_save_root = Path(Root_Path + str('/audio_images'))\n",
    "Train_audio_image_save_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "## File 내부 확인 \n",
    "file_list = os.listdir(Root_Path)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Audio File info ##\n",
    "#####################\n",
    "\n",
    "def get_audio_info(filepath):\n",
    "    with SoundFile(filepath) as f:\n",
    "        sr = f.samplerate\n",
    "        frames = f.frames\n",
    "        duration = float(frames)/sr\n",
    "        \n",
    "    return {'frames': frames, 'sr':sr, 'duration': duration}\n",
    "\n",
    "#오디오 파일에서 sr, running_time, frame 이 제일 중요한 정보기 때문에 이것들만 dic에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 15718, 31437, 47155, 62874]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "## 데이터셋이 클때 분할하기 위한 테크닉      ##\n",
    "##   이거 한 후에 make_df함수에서 쓰면 됨    ##\n",
    "###############################################\n",
    "\n",
    "Part_id = 0\n",
    "Part_indexs = np.linspace(0, 62874, 5)  #birdclef 가 62874개라 5분할\n",
    "Part_indexs = list(map(int, Part_indexs)) #분할한후 index로 쓸것이기때문에 int로 치환\n",
    "\n",
    "Part_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "##       Metadata + Audio_info 해서           ##\n",
    "##              DataFrame 생성                ##\n",
    "################################################\n",
    "\n",
    "def make_df(n_splits = 5, seed = seed, nrows = None):\n",
    "    \n",
    "    df = pd.read_csv(Train_metadata_root, nrows=nrows) #전체열 다 불러옴\n",
    "    Label_IDS = {label: label_id for label_id, label in enumerate(sorted(df['primary_label'].unique()))}  #고유종마다 ids 부여, ex 참새 = 0, 비둘기 = 1\n",
    "\n",
    "    \n",
    "    df = df.iloc[Part_indexs[Part_id] : Part_indexs[Part_id + 1]] #5분할중에 한파트\n",
    "    df['label_id'] = df['primary_label'].map(Label_IDS) ##Primary Label을 기준으로 같은 종마다 같은 Label_IDS 배정 ex.참새_1 = 0, 참새_2 = 0, 비둘기 = 1 \n",
    "    df['filepath'] = [str(Train_short_root/primary_label/filename) for primary_label, filename in zip(df.primary_label, df.filename)] #df에 file_path 추가\n",
    "\n",
    "    \n",
    "    pool = joblib.Parallel(6) ##병렬처리해서 속도up\n",
    "    mapper = joblib.delayed(get_audio_info) #get_audio_info 함수\n",
    "    tasks = [mapper(filepath) for filepath in df.filepath]\n",
    "    # df의 filepath열에 저장된 filepath를 get_audio_info에 넣고 모든 병렬처리 끝날때까지 기다리도록 설정\n",
    "    \n",
    "    \n",
    "    audio_info_index = []\n",
    "    for i in range( Part_indexs[Part_id], Part_indexs[Part_id + 1] ):\n",
    "        audio_info_index.append(i)\n",
    "        \n",
    "    df = pd.concat([df, pd.DataFrame( pool(tqdm(tasks)), index=audio_info_index )], axis=1, sort=False) #원래df 옆에 task한거(get_audio_info 결과) 붙임\n",
    "    \n",
    "    \n",
    "    #나중에 K-Fold 쓰기위해서 Fold할 number를 df에 labeling\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "    splits = skf.split(np.arange(len(df)), y=df.label_id.values)\n",
    "    df['fold'] = -1\n",
    "    \n",
    "    for fold, (train_set, val_set) in enumerate(splits):\n",
    "        df.loc[df.index[val_set], 'fold'] = fold\n",
    "    \n",
    "    return Label_IDS, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "##                                   ##  \n",
    "## 음성처리 위한 Melspectrogram 계산 ## \n",
    "##                                   ##\n",
    "#######################################\n",
    "\n",
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs['n_fft'] = kwargs.get('n_fft', self.sr//10) ##SR//10으로 n_fft 설정\n",
    "        kwargs['hop_length'] = kwargs.get('hop_length', self.sr//(10*4)) ##hop length == fft마다 겹치는 길이\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    \n",
    "    def __call__(self, audio):\n",
    "        \n",
    "        melspec = lb.feature.melspectrogram(\n",
    "            audio, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs\n",
    "        )\n",
    "        melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "        \n",
    "        return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "##          Mel Image normalize        ##   \n",
    "## 이미지 노말라이징 안하면 너무 밝음  ##\n",
    "#########################################\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "    \n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##          Crop Padding            ##   \n",
    "## 규격에 맞게 사이즈 trimming 하기 ##\n",
    "######################################\n",
    "\n",
    "def crop_or_pad(y, length, is_train=True, start=None):\n",
    "    # y가 규격보다 짧으면\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))]) ## 부족한 길이를 0우로 padding 함\n",
    "        \n",
    "        n_repeats = length // len(y)\n",
    "        epsilon = length % len(y)\n",
    "        \n",
    "        y= np.concatenate([y]*n_repeats + [y[:epsilon]]) ##적당히 채워줌\n",
    "        \n",
    "    # y가 규격보다 길면    \n",
    "    elif len(y) > length:\n",
    "        if not is_train:\n",
    "            start = start or 0\n",
    "        else:\n",
    "            start = start or np.random.randint(len(y) - length)\n",
    "            \n",
    "        y = y[start : start + length] ##이러면 length짜리 y로 변경됨\n",
    "        \n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################                  \n",
    "##   Audio to Image       ##\n",
    "############################\n",
    "\n",
    "\n",
    "class AudioToImage:\n",
    "    def __init__(self, sr=SR, n_mels=128, fmin=0, fmax=None, duration=Duration, step=None, res_type='kaiser_fast', resample=True):\n",
    "        \n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax or self.sr//2 ##안넣으면 nyquist로 씀\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr #audio들은 길이가 다 다르기 때문에 audio_length만큼씩 같은 길이로 토막내서 보관\n",
    "        self.step = step or self.audio_length\n",
    "        self.res_type = res_type\n",
    "        self.resample = resample\n",
    "        \n",
    "        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n",
    "        \n",
    "    def audio_to_image(self, audio):\n",
    "        melspec = self.mel_spec_computer(audio)\n",
    "        image = mono_to_color(melspec)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __call__(self, row, save=True):\n",
    "        audio, orig_sr = sf.read(row.filepath, dtype='float32')\n",
    "        \n",
    "        #전처리 Audio_to_img 하기전에 음성과 우리의 sr이 안맞으면 안되기때문에..\n",
    "        if self.resample and orig_sr != self.sr: #resampling이 요청되거나(sampling rate가 안맞을때)\n",
    "            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "          \n",
    "        \n",
    "        ##본처리\n",
    "        \n",
    "        #먼저 음성마다 다른 길이를 맞춰주기 위해서 같은 길이로 샘플링할것임\n",
    "        # audio길이를 i:i+audio_len 즉 audio_len만큼 읽을건데, i범위는 0부터 총길이-원하는길이 , 원하는 길이 간격으로\n",
    "        # 즉 audios에 저장 되는것은 [0~audio_len, audio_len~2*audio_len, ..... ,x*audio_len~총길이] 이런식으로 샘플링해서 저장\n",
    "        audios = [audio[i: i+self.audio_length] for i in range(0, max(1, len(audio) - self.audio_length+1), self.step)]\n",
    "        # 마지막 (x*audio_len ~ 총 길이) 인 샘플은 총 길이가 (x+1)*audio_len 이 아니면 더 짧게 나올것임, 따라서 crop_padding해줌\n",
    "        audios[-1] = crop_or_pad(audios[-1], length=self.audio_length)\n",
    "        \n",
    "        #audios에 잘라서 넣은 audio들을\n",
    "        images = [self.audio_to_image(audio) for audio in audios]\n",
    "        images = np.stack(images)\n",
    "        \n",
    "        \n",
    "        #저장\n",
    "        if save:\n",
    "            path = Train_audio_image_save_root/f\"{row.primary_label}/{row.filename}.npy\"\n",
    "            path.parent.mkdir(exist_ok=True, parents=True) #parent는 상위경로도 생성한다는 뜻\n",
    "            np.save(str(path), images)\n",
    "        \n",
    "        else:\n",
    "            return row.filename, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio to Image 실행\n",
    "\n",
    "def get_audios_as_images(df):\n",
    "    pool = joblib.Parallel(2)\n",
    "    converter = AudioToImage(step=int(Duration*0.666*SR)) ##Step ==audio_length\n",
    "    mapper = joblib.delayed(converter)\n",
    "    tasks = [mapper(row) for row in df.itertuples(False)]\n",
    "\n",
    "    pool(tqdm(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c3a5da2abc4cd3adc64e9b9e10b81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede1d3849784155911ecc6ce70151e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e6fefbed4520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLabel_IDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Label_IDS 객채를 json_file에 넣음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mget_audios_as_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##이건 넘어갔다가 Audio_do_image 파트 보고 다시올것.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-07c09c1f2700>\u001b[0m in \u001b[0;36mget_audios_as_images\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch17_p38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch17_p38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch17_p38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch17_p38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch17_p38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 합친 Data_Frame 생성 (Part_id == 0 이기 때문에 5개를 loop로 5개 다 돌려야 전체 데이터 셋임)\n",
    "for Part_id in range(4):\n",
    "    Label_IDS, df = make_df()\n",
    "\n",
    "    # 새 df를 csv로 저장\n",
    "    df.to_csv(Root_Path + f'/rich_train_metadata_{Part_id}.csv', index=True)\n",
    "    \n",
    "    #json이 data 전송할때 더 유리하다고 함, json도 같이 저장해줍시다.\n",
    "    with open(Root_Path + f'/Label_IDS_{Part_id}.json', 'w') as f: ## Label_IDS.json 이름의 파일을 'w'rite모드로 열어서\n",
    "        json.dump(Label_IDS, f) #Label_IDS 객채를 json_file에 넣음\n",
    "        \n",
    "    get_audios_as_images(df) ##이건 넘어갔다가 Audio_do_image 파트 보고 다시올것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# For example.. we can see longest duration mel image\n",
    "row_example = df.loc[df.duration.idxmax()]\n",
    "mels_example = np.load(str((Train_audio_image_save_root/row.primary_label/row.filename).as_posix() + '.npy'))\n",
    "print(mels_example.shape)\n",
    "lbd.specshow(mels_example[0])\n",
    "# as_posix 쓰면 str 안에 존재하는 \\ 가 | 로 바뀜\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17_p38",
   "language": "python",
   "name": "pytorch17_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "'''\n",
    "                 PIPE LINE 3\n",
    "          모델 불러와서 평가하기\n",
    "                                              '''\n",
    "###############################################\n",
    "\n",
    "'''\n",
    "PipeLine 으로 따로따로 작업하려면\n",
    "\n",
    "class MelSpecComputer\n",
    "def mono_to_color\n",
    "class BirdCLEFDataset\n",
    "불러올것\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from  soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from  IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from  ast import literal_eval\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Seed Setting ##\n",
    "##################\n",
    "\n",
    "def make_seed(seed = 499):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "make_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Path manage ##\n",
    "#################\n",
    "\n",
    "Root_Path = '/Users/ansgh/PycharmProjects/kaggle_notebook/input/birdclef-2021'\n",
    "\n",
    "Train_short_root = Path(Root_Path + str('/train_short_audio'))\n",
    "Train_metadata_root = Path(Root_Path + str('/train_metadata.csv'))\n",
    "\n",
    "Train_audio_image_save_root = Path(Root_Path + str('/audio_images'))\n",
    "Train_audio_image_save_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "## File 내부 확인 \n",
    "file_list = os.listdir(Root_Path)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 397\n",
    "SR = 32_000\n",
    "DURATION = 5\n",
    "THRESH = 0.25\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/test_soundscapes\")\n",
    "SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "TARGET_PATH = None\n",
    "    \n",
    "    \n",
    "## Test Audio 에 아무것도 없으면(룰 상 제출용 커밋할때만 test_soundscapes에 접근가능하기때문에 연습때는 train_soundscapes꺼 씀)\n",
    "if not len(list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):\n",
    "    TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/train_soundscapes\")\n",
    "    SAMPLE_SUB_PATH = None\n",
    "    # SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "    TARGET_PATH = Path(\"../input/birdclef-2021/train_soundscape_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "##                                   ##  \n",
    "## 음성처리 위한 Melspectrogram 계산 ## \n",
    "##                                   ##\n",
    "#######################################\n",
    "\n",
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs['n_fft'] = kwargs.get('n_fft', self.sr//10) ##SR//10으로 n_fft 설정\n",
    "        kwargs['hop_length'] = kwargs.get('hop_length', self.sr//(10*4)) ##hop length == fft마다 겹치는 길이\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    \n",
    "    def __call__(self, audio):\n",
    "        \n",
    "        melspec = lb.feature.melspectrogram(\n",
    "            audio, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs\n",
    "        )\n",
    "        melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "        \n",
    "        return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "##          Mel Image normalize        ##   \n",
    "## 이미지 노말라이징 안하면 너무 밝음  ##\n",
    "#########################################\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "    \n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##          Crop Padding            ##   \n",
    "## 규격에 맞게 사이즈 trimming 하기 ##\n",
    "######################################\n",
    "\n",
    "def crop_or_pad(y, length, is_train=True, start=None):\n",
    "    # y가 규격보다 짧으면\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))]) ## 부족한 길이를 0우로 padding 함\n",
    "        \n",
    "        n_repeats = length // len(y)\n",
    "        epsilon = length % len(y)\n",
    "        \n",
    "        y= np.concatenate([y]*n_repeats + [y[:epsilon]]) ##적당히 채워줌\n",
    "        \n",
    "    # y가 규격보다 길면    \n",
    "    elif len(y) > length:\n",
    "        if not is_train:\n",
    "            start = start or 0\n",
    "        else:\n",
    "            start = start or np.random.randint(len(y) - length)\n",
    "            \n",
    "        y = y[start : start + length] ##이러면 length짜리 y로 변경됨\n",
    "        \n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "##        Dataset 만들기          ##\n",
    "##    numpy 3층으로 image 쌓고    ##\n",
    "##     label은  smoothing 해서    ##\n",
    "##         image, label 반환      ##\n",
    "####################################\n",
    "\n",
    "class BirdClefDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, audio_image_store, meta, sr=SR, is_train=True, num_classes=Num_classes, duration=Duration):\n",
    "        \n",
    "        self.audio_image_store = audio_image_store ##audio np array랑 filename 저장된 dic\n",
    "        self.meta = meta.copy().reset_index(drop=True) ##meta는 df\n",
    "        self.sr = sr\n",
    "        self.is_train = is_train\n",
    "        self.num_classes = num_classes\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        \n",
    "    \n",
    "    def normalize(self, image):\n",
    "        image = image.astype('float32', copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "    \n",
    "    \n",
    "    def find_mid_img(self, image):\n",
    "        list = []\n",
    "        for i in range(len(image)):\n",
    "            list.append(image[i].sum())\n",
    "        \n",
    "        list = sorted(list)\n",
    "        list[len(image)//2]\n",
    "    \n",
    "        for i in range(len(image)):\n",
    "            list[i] == image[i].sum()\n",
    "            return image[i]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##이 dataset의 단점이 있는 파트\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]  #df에서 데이터 하나 불러옴\n",
    "        image = self.audio_image_store[row.filename] #불러온 데이터의 filename으로 audio_image_store에서 image에 해당하는 np array 받아서 image에 저장\n",
    "        \n",
    "        \n",
    "        #방법 1\n",
    "        #image에 저장된 np array는 (x, 128, 281)로써, 음성(.ogg)가 25초라면 7초씩 저장했으므로 x==4, 이미지크기==128,281 이라는 뜻. len(image)는 맨 앞 x를 반환한다.\n",
    "        #즉 윗줄이 뜻하는 것은 AudioToImage 클래스로 image에 저장시킨 7초짜리 x개의 영상중 랜덤으로 하나만 쓰겠다는 뜻이다.\n",
    "        #이것은 단점이 되는데 만약 랜덤하게 뽑은 음성이 표본을 제대로 반영하지 못할수 있기 때문이다.\n",
    "        image = image[np.random.choice(len(image))] \n",
    "        \n",
    "        \n",
    "        #방법2\n",
    "        # 랜덤하게 안뽑고 이미지 중에서 노이즈는 상수라고 쳤을때 신호가 있으면 값이 더 커질것.\n",
    "        # 따라서 중간값 혹은 최댓값을 갖게 뽑아서 써보자\n",
    "        ##image = self.find_mid_img(image)\n",
    "        \n",
    "        \n",
    "        image = self.normalize(image)\n",
    "        \n",
    "        ## Label smoothing. 해당 라벨은 0.995, 나머지는 0.0025로 초기화\n",
    "        t = np.zeros(self.num_classes, dtype=np.float32) + 0.0025 \n",
    "        t[row.label_id] = 0.995\n",
    "        \n",
    "        return image, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(TEST_AUDIO_ROOT).glob(\"*.ogg\")],\n",
    "    columns = [\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n",
    ")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 메타데이터(정답지) 불러오기\n",
    "df_train = pd.read_csv(\"../input/birdclef-2021/train_metadata.csv\")\n",
    "\n",
    "LABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\n",
    "INV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = BirdCLEFDataset(data=data)\n",
    "len(test_data), test_data[0].shape, test_data[1].shape\n",
    "# 20 -> train_soundscape에 20개 있음\n",
    "# 120 -> 10분(각 train_soundscape음성) / 5초\n",
    "# 3 - > normalize에서 3쌓음\n",
    "# 128, 201 -> 이미지 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path, num_classes=NUM_CLASSES):\n",
    "    net = models.resnet152(pretrained = False)\n",
    "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "    dummy_device = torch.device(\"cpu\")\n",
    "    d = torch.load(checkpoint_path, map_location=dummy_device)\n",
    "    for key in list(d.keys()):\n",
    "        d[key.replace(\"model.\", \"\")] = d.pop(key)\n",
    "    net.load_state_dict(d)\n",
    "    net = net.to(DEVICE)\n",
    "    net = net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = [\n",
    "    Path(\"../input/bird-clef/resnet152_sr32000_d7_v1_v1/birdclef_resnet152_fold0_epoch_00_f1_val_01435_20210513145723.pth\"),\n",
    "]\n",
    "\n",
    "\n",
    "nets = [\n",
    "        load_net(checkpoint_path.as_posix()) for checkpoint_path in checkpoint_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Threshold 보다 높은 값만 pred라는 list에 저장\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_thresh_preds(out, thresh=None):\n",
    "    thresh = thresh or THRESH\n",
    "    o = (-out).argsort(1)\n",
    "    npreds = (out > thresh).sum(1)\n",
    "    preds = []\n",
    "    for oo, npred in zip(o, npreds):\n",
    "        preds.append(oo[:npred].cpu().numpy().tolist())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pred라는 list를 받아서 그 안에 새이름이 있으면 keep, 없으면 'nocall'로 변경\n",
    "def get_bird_names(preds):\n",
    "    bird_names = []\n",
    "    for pred in preds:\n",
    "        if not pred:\n",
    "            bird_names.append(\"nocall\")\n",
    "        else:\n",
    "            bird_names.append(\" \".join([INV_LABEL_IDS[bird_id] for bird_id in pred]))\n",
    "    return bird_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict 실행해서 label 확률표 반환\n",
    "\n",
    "def predict(nets, test_data, names=True):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for idx in  tqdm(list(range(len(test_data)))):\n",
    "            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n",
    "            pred = 0.\n",
    "            for net in nets:\n",
    "                o = net(xb)\n",
    "                o = torch.sigmoid(o)\n",
    "\n",
    "                pred += o\n",
    "\n",
    "            pred /= len(nets)\n",
    "            \n",
    "            if names:\n",
    "                pred = get_bird_names(get_thresh_preds(pred))\n",
    "\n",
    "            preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = predict(nets, test_data, names=False)\n",
    "print(len(pred_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##새 이름 list로 전\n",
    "preds = [get_bird_names(get_thresh_preds(pred, thresh=THRESH)) for pred in pred_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##    submission 만들기 위한 작업   ##\n",
    "######################################\n",
    "\n",
    "\n",
    "def preds_as_df(data, preds):\n",
    "    sub = {\n",
    "        \"row_id\": [],\n",
    "        \"birds\": [],\n",
    "    }\n",
    "    \n",
    "    for row, pred in zip(data.itertuples(False), preds):\n",
    "        row_id = [f\"{row.id}_{row.site}_{5*i}\" for i in range(1, len(pred)+1)]\n",
    "        sub[\"birds\"] += pred\n",
    "        sub[\"row_id\"] += row_id\n",
    "        \n",
    "    sub = pd.DataFrame(sub)\n",
    "    \n",
    "    if SAMPLE_SUB_PATH:\n",
    "        sample_sub = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\"])\n",
    "        sub = sample_sub.merge(sub, on=\"row_id\", how=\"left\")\n",
    "        sub[\"birds\"] = sub[\"birds\"].fillna(\"nocall\")\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = preds_as_df(data, preds)\n",
    "print(sub.shape)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##         성능 확인하기            ##\n",
    "######################################\n",
    "\n",
    "\n",
    "def get_metrics(s_true, s_pred):\n",
    "    s_true = set(s_true.split())\n",
    "    s_pred = set(s_pred.split())\n",
    "    n, n_true, n_pred = len(s_true.intersection(s_pred)), len(s_true), len(s_pred)\n",
    "    \n",
    "    prec = n/n_pred\n",
    "    rec = n/n_true\n",
    "    f1 = 2*prec*rec/(prec + rec) if prec + rec else 0\n",
    "    \n",
    "    return {\"f1\": f1, \"prec\": prec, \"rec\": rec, \"n_true\": n_true, \"n_pred\": n_pred, \"n\": n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TARGET_PATH:\n",
    "    sub_target = pd.read_csv(TARGET_PATH)\n",
    "    sub_target = sub_target.merge(sub, how=\"left\", on=\"row_id\")\n",
    "    \n",
    "    print(sub_target[\"birds_x\"].notnull().sum(), sub_target[\"birds_x\"].notnull().sum())\n",
    "    assert sub_target[\"birds_x\"].notnull().all()\n",
    "    assert sub_target[\"birds_y\"].notnull().all()\n",
    "    \n",
    "    df_metrics = pd.DataFrame([get_metrics(s_true, s_pred) for s_true, s_pred in zip(sub_target.birds_x, sub_target.birds_y)])\n",
    "    \n",
    "    print(df_metrics.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_target[sub_target.birds_y != \"nocall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_target[sub_target.birds_x != \"nocall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17_p38",
   "language": "python",
   "name": "pytorch17_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
